#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
fx_backtest_fixed_complete.py - FXã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆ + 3å±¤æˆ¦ç•¥ï¼‰
CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ã‚’å®Œå…¨è§£æ±ºã—ã€ãƒ‡ãƒãƒƒã‚°æ©Ÿèƒ½ã‚’å¼·åŒ–
BASE/EXPAND/ATR 3å±¤æˆ¦ç•¥ã‚’å®Ÿè£…
"""

import os
import pandas as pd
import numpy as np
import zipfile
import glob
import io
import re
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
import logging
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# chardetã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’å®‰å…¨ã«è¡Œã†
try:
    import chardet
    CHARDET_AVAILABLE = True
except ImportError:
    CHARDET_AVAILABLE = False
    print("âš ï¸  chardet ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    print("   ã‚ˆã‚Šæ­£ç¢ºãªæ–‡å­—ã‚³ãƒ¼ãƒ‰æ¤œå‡ºã®ãŸã‚ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™:")
    print("   pip install chardet")

# åŸºæœ¬è¨­å®š
BASE_DIR = Path(__file__).resolve().parent
ENTRYPOINT_DIR = BASE_DIR / "entrypoint_fx"
# ENTRYPOINT_DIR = BASE_DIR / "entrypoint_fx_ã‚ˆãã°ã‚Š"
HISTORICAL_DATA_DIR = BASE_DIR / "input"
BACKTEST_RESULT_DIR = BASE_DIR / "backtest_results"
BACKTEST_RESULT_DIR.mkdir(exist_ok=True)

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(BACKTEST_RESULT_DIR / "backtest_fixed_complete.log", encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class FXBacktestSystemComplete:
    """FXãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆ + ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹æ©Ÿèƒ½ + 3å±¤æˆ¦ç•¥ï¼‰"""
    
    def __init__(self, stop_loss_pips=None, take_profit_pips=None):
        """åˆæœŸåŒ–
        
        Parameters:
        -----------
        stop_loss_pips : float, optional
            ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹è¨­å®šï¼ˆpipsï¼‰ã€‚Noneã®å ´åˆã¯ç„¡åŠ¹
        take_profit_pips : float, optional
            ãƒ†ã‚¤ã‚¯ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆè¨­å®šï¼ˆpipsï¼‰ã€‚Noneã®å ´åˆã¯ç„¡åŠ¹
        """
        self.entrypoint_files = []
        self.backtest_results = []
        self.summary_stats = {}
        
        # ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ãƒ»ãƒ†ã‚¤ã‚¯ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆè¨­å®š
        self.stop_loss_pips = stop_loss_pips
        self.take_profit_pips = take_profit_pips
        
        # é€šè²¨ãƒšã‚¢è¨­å®š
        self.currency_settings = {
            "USDJPY": {"pip_value": 0.01, "pip_multiplier": 100},
            "EURJPY": {"pip_value": 0.01, "pip_multiplier": 100},
            "GBPJPY": {"pip_value": 0.01, "pip_multiplier": 100},
            "AUDJPY": {"pip_value": 0.01, "pip_multiplier": 100},
            "CHFJPY": {"pip_value": 0.01, "pip_multiplier": 100},
            "CADJPY": {"pip_value": 0.01, "pip_multiplier": 100},
            "NZDJPY": {"pip_value": 0.01, "pip_multiplier": 100},
            "EURUSD": {"pip_value": 0.0001, "pip_multiplier": 10000},
            "GBPUSD": {"pip_value": 0.0001, "pip_multiplier": 10000},
            "AUDUSD": {"pip_value": 0.0001, "pip_multiplier": 10000},
            "NZDUSD": {"pip_value": 0.0001, "pip_multiplier": 10000},
            "USDCHF": {"pip_value": 0.0001, "pip_multiplier": 10000}
        }
        
        logger.info("FXãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆ + ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹æ©Ÿèƒ½ + 3å±¤æˆ¦ç•¥ï¼‰ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
        if self.stop_loss_pips:
            logger.info(f"ğŸ“‰ ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹è¨­å®š: {self.stop_loss_pips} pips")
        if self.take_profit_pips:
            logger.info(f"ğŸ“ˆ ãƒ†ã‚¤ã‚¯ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆè¨­å®š: {self.take_profit_pips} pips")
        logger.info("ğŸ¯ 3å±¤æˆ¦ç•¥: BASE/EXPAND/ATR ã‚’æœ‰åŠ¹åŒ–")
    
    def decide_layer(
            self,
            spread      : float,
            true_range  : float,
            dir_5m      : bool,
            dir_15m     : bool,
            dir_1h      : bool,
            sp30        : float,
            sp40        : float,
            tr40        : float,
            atr14       : float,
            atr14_med   : float
    ) -> str:
        """
        BASE : ä½ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ & ä½ãƒœãƒ© & 5â€Šåˆ†ã¨15â€Šåˆ†ãŒåŒä¸€æ–¹å‘
        EXPAND : ä¸­åº¸ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ä»¥ä¸‹ & MFT å®Œå…¨ä¸€è‡´ & å‹¢ã„(ATR é«˜)
        ATR : ä¸Šè¨˜ä»¥å¤–
        """

        # â”€â”€ BASE â”€â”€
        if (spread <= sp30) and (true_range <= tr40) and (dir_5m == dir_15m):
            return "BASE"

        # â”€â”€ EXPAND â”€â”€
        if (spread <= sp40) and dir_5m and dir_15m and dir_1h and (atr14 > atr14_med):
            return "EXPAND"

        # â”€â”€ ATR â”€â”€
        return "ATR"

    def get_layer_sl_tp(self, layer: str, atr14: float) -> tuple[int, int]:
        """
        BASE : SL 8 / TP 14
        EXPAND : SL 12 / TP 30
        ATR : SL = int(ATR14Ã—1.3) / TP = SLÃ—2
        """
        if layer == "BASE":
            return 8, 14

        if layer == "EXPAND":
            return 12, 30

        # layer == "ATR"
        sl = int(atr14 * 1.3)
        return sl, sl * 2

    @staticmethod
    def _calc_day_thresholds(df_day: pd.DataFrame) -> dict:
        """
        BASEï¼EXPAND åˆ¤å®šã«ç”¨ã„ã‚‹åˆ†ä½ç‚¹ã‚’æ—¥æ¬¡ã§è¨ˆç®—ã—ã¦è¿”ã™
        """
        return {
            "sp30"         : df_day["spread"].quantile(0.30),
            "sp35"         : df_day["spread"].quantile(0.35),
            "sp40"         : df_day["spread"].quantile(0.40),
            "tr40"         : df_day["true_range"].quantile(0.40),
            "tr50"         : df_day["true_range"].quantile(0.50),
            "atr14_median" : df_day["atr14"].median(),
        }

    def calculate_stop_loss_price(self, entry_price, direction, currency_pair):
        """ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ä¾¡æ ¼ã‚’è¨ˆç®—"""
        if not self.stop_loss_pips:
            return None
        
        settings = self.currency_settings.get(currency_pair.replace('_', ''))
        if not settings:
            pip_value = 0.01 if 'JPY' in currency_pair else 0.0001
        else:
            pip_value = settings['pip_value']
        
        if direction.upper() in ['LONG', 'BUY']:
            # Longãƒã‚¸ã‚·ãƒ§ãƒ³ã®å ´åˆã€ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼ã‚ˆã‚Šä¸‹ã«ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹
            stop_loss_price = entry_price - (self.stop_loss_pips * pip_value)
        else:  # SHORT, SELL
            # Shortãƒã‚¸ã‚·ãƒ§ãƒ³ã®å ´åˆã€ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼ã‚ˆã‚Šä¸Šã«ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹
            stop_loss_price = entry_price + (self.stop_loss_pips * pip_value)
        
        return stop_loss_price
    
    def calculate_take_profit_price(self, entry_price, direction, currency_pair):
        """ãƒ†ã‚¤ã‚¯ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆä¾¡æ ¼ã‚’è¨ˆç®—"""
        if not self.take_profit_pips:
            return None
        
        settings = self.currency_settings.get(currency_pair.replace('_', ''))
        if not settings:
            pip_value = 0.01 if 'JPY' in currency_pair else 0.0001
        else:
            pip_value = settings['pip_value']
        
        if direction.upper() in ['LONG', 'BUY']:
            # Longãƒã‚¸ã‚·ãƒ§ãƒ³ã®å ´åˆã€ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼ã‚ˆã‚Šä¸Šã«ãƒ†ã‚¤ã‚¯ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆ
            take_profit_price = entry_price + (self.take_profit_pips * pip_value)
        else:  # SHORT, SELL
            # Shortãƒã‚¸ã‚·ãƒ§ãƒ³ã®å ´åˆã€ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼ã‚ˆã‚Šä¸‹ã«ãƒ†ã‚¤ã‚¯ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆ
            take_profit_price = entry_price - (self.take_profit_pips * pip_value)
        
        return take_profit_price
    
    def check_stop_loss_hit(self, current_price, stop_loss_price, direction):
        """ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ãŒãƒ’ãƒƒãƒˆã—ãŸã‹ãƒã‚§ãƒƒã‚¯"""
        if stop_loss_price is None:
            return False
        
        if direction.upper() in ['LONG', 'BUY']:
            # Longãƒã‚¸ã‚·ãƒ§ãƒ³ï¼šç¾åœ¨ä¾¡æ ¼ãŒã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ä¾¡æ ¼ä»¥ä¸‹
            return current_price <= stop_loss_price
        else:  # SHORT, SELL
            # Shortãƒã‚¸ã‚·ãƒ§ãƒ³ï¼šç¾åœ¨ä¾¡æ ¼ãŒã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ä¾¡æ ¼ä»¥ä¸Š
            return current_price >= stop_loss_price
    
    def check_take_profit_hit(self, current_price, take_profit_price, direction):
        """ãƒ†ã‚¤ã‚¯ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆãŒãƒ’ãƒƒãƒˆã—ãŸã‹ãƒã‚§ãƒƒã‚¯"""
        if take_profit_price is None:
            return False
        
        if direction.upper() in ['LONG', 'BUY']:
            # Longãƒã‚¸ã‚·ãƒ§ãƒ³ï¼šç¾åœ¨ä¾¡æ ¼ãŒãƒ†ã‚¤ã‚¯ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆä¾¡æ ¼ä»¥ä¸Š
            return current_price >= take_profit_price
        else:  # SHORT, SELL
            # Shortãƒã‚¸ã‚·ãƒ§ãƒ³ï¼šç¾åœ¨ä¾¡æ ¼ãŒãƒ†ã‚¤ã‚¯ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆä¾¡æ ¼ä»¥ä¸‹
            return current_price <= take_profit_price
    
    def monitor_position_with_stop_loss(self, df_historical, entry_time, exit_time, entry_price, direction, currency_pair):
        """ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ãƒ»ãƒ†ã‚¤ã‚¯ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆç›£è¦–ä»˜ããƒã‚¸ã‚·ãƒ§ãƒ³ç®¡ç†ï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆï¼‰
        
        Returns:
        --------
        dict: {
            'exit_price': float,
            'actual_exit_time': datetime,
            'exit_reason': str,
            'max_favorable_pips': float,
            'max_adverse_pips': float
        }
        """
        try:
            # ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ãƒ»ãƒ†ã‚¤ã‚¯ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆä¾¡æ ¼ã‚’è¨ˆç®—
            stop_loss_price = self.calculate_stop_loss_price(entry_price, direction, currency_pair)
            take_profit_price = self.calculate_take_profit_price(entry_price, direction, currency_pair)
            
            logger.debug(f"       SL: {stop_loss_price}, TP: {take_profit_price}")
            
            # æ™‚åˆ»ã‚’datetimeã«å¤‰æ›
            entry_datetime = pd.to_datetime(entry_time)
            exit_datetime = pd.to_datetime(exit_time)
            
            logger.debug(f"       ç›£è¦–æœŸé–“: {entry_datetime} ï½ {exit_datetime}")
            
            # ãƒ‡ãƒ¼ã‚¿ã®æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯
            if df_historical.empty:
                logger.warning("       å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                return None
            
            if 'timestamp' not in df_historical.columns:
                logger.warning(f"       timestampã‚«ãƒ©ãƒ ãŒã‚ã‚Šã¾ã›ã‚“: {list(df_historical.columns)}")
                return None
            
            # ãƒ‡ãƒ¼ã‚¿ã®æ™‚é–“ç¯„å›²ã‚’ç¢ºèª
            df_sorted = df_historical.sort_values('timestamp').copy()
            data_min_time = df_sorted['timestamp'].min()
            data_max_time = df_sorted['timestamp'].max()
            
            logger.debug(f"       ãƒ‡ãƒ¼ã‚¿ç¯„å›²: {data_min_time} ï½ {data_max_time}")
            
            # ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ™‚åˆ»ã®èª¿æ•´ï¼ˆãƒ‡ãƒ¼ã‚¿ç¯„å›²å†…ã«èª¿æ•´ï¼‰
            adjusted_entry_time = entry_datetime
            if entry_datetime < data_min_time:
                adjusted_entry_time = data_min_time
                logger.warning(f"       ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ™‚åˆ»ã‚’èª¿æ•´: {entry_datetime} -> {adjusted_entry_time}")
            elif entry_datetime > data_max_time:
                adjusted_entry_time = data_max_time
                logger.warning(f"       ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ™‚åˆ»ã‚’èª¿æ•´: {entry_datetime} -> {adjusted_entry_time}")
            
            # ã‚¨ã‚°ã‚¸ãƒƒãƒˆæ™‚åˆ»ã®èª¿æ•´ï¼ˆãƒ‡ãƒ¼ã‚¿ç¯„å›²å†…ã«èª¿æ•´ï¼‰
            adjusted_exit_time = exit_datetime
            if exit_datetime < data_min_time:
                adjusted_exit_time = data_min_time
                logger.warning(f"       ã‚¨ã‚°ã‚¸ãƒƒãƒˆæ™‚åˆ»ã‚’èª¿æ•´: {exit_datetime} -> {adjusted_exit_time}")
            elif exit_datetime > data_max_time:
                adjusted_exit_time = data_max_time
                logger.warning(f"       ã‚¨ã‚°ã‚¸ãƒƒãƒˆæ™‚åˆ»ã‚’èª¿æ•´: {exit_datetime} -> {adjusted_exit_time}")
            
            # èª¿æ•´å¾Œã®æ™‚åˆ»ã§æœŸé–“ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            mask = (df_sorted['timestamp'] >= adjusted_entry_time) & (df_sorted['timestamp'] <= adjusted_exit_time)
            period_data = df_sorted[mask].copy()
            
            # æœŸé–“ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®å ´åˆã®å¯¾å‡¦
            if period_data.empty:
                logger.warning(f"       æœŸé–“ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚æœ€è¿‘æ¥ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™")
                # ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ™‚åˆ»ã«æœ€ã‚‚è¿‘ã„ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                df_sorted['time_diff'] = abs(df_sorted['timestamp'] - adjusted_entry_time)
                closest_entry_idx = df_sorted['time_diff'].idxmin()
                
                # ã‚¨ã‚°ã‚¸ãƒƒãƒˆæ™‚åˆ»ã«æœ€ã‚‚è¿‘ã„ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                df_sorted['time_diff'] = abs(df_sorted['timestamp'] - adjusted_exit_time)
                closest_exit_idx = df_sorted['time_diff'].idxmin()
                
                # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‹ã‚‰ã‚¨ã‚°ã‚¸ãƒƒãƒˆã¾ã§ã®ç¯„å›²ã‚’å–å¾—
                start_idx = min(closest_entry_idx, closest_exit_idx)
                end_idx = max(closest_entry_idx, closest_exit_idx)
                
                period_data = df_sorted.iloc[start_idx:end_idx+1].copy()
                
                if period_data.empty:
                    # ãã‚Œã§ã‚‚ç©ºã®å ´åˆã¯ã€æœ€è¿‘æ¥ã®1ã¤ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨
                    period_data = df_sorted.iloc[[closest_entry_idx]].copy()
                    logger.warning(f"       å˜ä¸€ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨: {period_data.iloc[0]['timestamp']}")
            
            logger.debug(f"       ç›£è¦–ãƒ‡ãƒ¼ã‚¿æ•°: {len(period_data)}")
            
            # ç›£è¦–ç”¨ã®ä¾¡æ ¼ã‚«ãƒ©ãƒ ã‚’æ±ºå®š
            if direction.upper() in ['LONG', 'BUY']:
                price_columns = ['close_bid', 'low_bid', 'high_bid', 'open_bid']
            else:  # SHORT, SELL
                price_columns = ['close_ask', 'low_ask', 'high_ask', 'open_ask']
            
            # åˆ©ç”¨å¯èƒ½ãªä¾¡æ ¼ã‚«ãƒ©ãƒ ã‚’é¸æŠ
            price_column = None
            for col in price_columns:
                if col in period_data.columns:
                    price_column = col
                    break
            
            if price_column is None:
                logger.warning(f"       ç›£è¦–ç”¨ä¾¡æ ¼ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {list(period_data.columns)}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ•°å€¤ã‚«ãƒ©ãƒ ã‚’æ¢ã™
                numeric_columns = period_data.select_dtypes(include=[np.number]).columns
                if len(numeric_columns) > 0:
                    price_column = numeric_columns[0]
                    logger.warning(f"       ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¾¡æ ¼ã‚«ãƒ©ãƒ ä½¿ç”¨: {price_column}")
                else:
                    logger.error(f"       ä½¿ç”¨å¯èƒ½ãªä¾¡æ ¼ã‚«ãƒ©ãƒ ãŒã‚ã‚Šã¾ã›ã‚“")
                    return None
            
            logger.debug(f"       ä½¿ç”¨ä¾¡æ ¼ã‚«ãƒ©ãƒ : {price_column}")
            
            # å«ã¿æç›Šã®è¿½è·¡
            max_favorable_pips = 0
            max_adverse_pips = 0
            
            # å„æ™‚ç‚¹ã§ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ãƒ»ãƒ†ã‚¤ã‚¯ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆã‚’ãƒã‚§ãƒƒã‚¯
            for idx, row in period_data.iterrows():
                if pd.isna(row[price_column]):
                    continue
                    
                current_price = float(row[price_column])
                current_time = row['timestamp']
                
                # ç¾åœ¨ã®pipsã‚’è¨ˆç®—
                current_pips = self.calculate_pips(entry_price, current_price, currency_pair, direction)
                
                # æœ€å¤§å«ã¿ç›Šãƒ»å«ã¿æã‚’æ›´æ–°
                if current_pips > max_favorable_pips:
                    max_favorable_pips = current_pips
                if current_pips < max_adverse_pips:
                    max_adverse_pips = current_pips
                
                # ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ãƒã‚§ãƒƒã‚¯
                if self.check_stop_loss_hit(current_price, stop_loss_price, direction):
                    logger.info(f"       ğŸ›‘ ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ãƒ’ãƒƒãƒˆ: {current_price} @ {current_time}")
                    return {
                        'exit_price': stop_loss_price,
                        'actual_exit_time': current_time,
                        'exit_reason': 'STOP_LOSS',
                        'max_favorable_pips': max_favorable_pips,
                        'max_adverse_pips': max_adverse_pips
                    }
                
                # ãƒ†ã‚¤ã‚¯ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆãƒã‚§ãƒƒã‚¯
                if self.check_take_profit_hit(current_price, take_profit_price, direction):
                    logger.info(f"       ğŸ¯ ãƒ†ã‚¤ã‚¯ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆãƒ’ãƒƒãƒˆ: {current_price} @ {current_time}")
                    return {
                        'exit_price': take_profit_price,
                        'actual_exit_time': current_time,
                        'exit_reason': 'TAKE_PROFIT',
                        'max_favorable_pips': max_favorable_pips,
                        'max_adverse_pips': max_adverse_pips
                    }
            
            # æ™‚é–“åˆ‡ã‚Œï¼ˆé€šå¸¸ã®ã‚¨ã‚°ã‚¸ãƒƒãƒˆï¼‰
            final_row = period_data.iloc[-1]
            final_price = float(final_row[price_column])
            final_time = final_row['timestamp']
            
            logger.debug(f"       â° æ™‚é–“åˆ‡ã‚Œã‚¨ã‚°ã‚¸ãƒƒãƒˆ: {final_price} @ {final_time}")
            return {
                'exit_price': final_price,
                'actual_exit_time': final_time,
                'exit_reason': 'TIME_EXIT',
                'max_favorable_pips': max_favorable_pips,
                'max_adverse_pips': max_adverse_pips
            }
            
        except Exception as e:
            logger.error(f"       ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            
            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
            try:
                if df_historical.empty:
                    return None
                
                # æœ€å¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨
                last_row = df_historical.iloc[-1]
                
                # ä¾¡æ ¼ã‚«ãƒ©ãƒ ã‚’æ¢ã™
                numeric_cols = df_historical.select_dtypes(include=[np.number]).columns
                if len(numeric_cols) > 0:
                    price_col = numeric_cols[0]
                    fallback_price = float(last_row[price_col])
                    fallback_time = last_row.get('timestamp', pd.Timestamp.now())
                    
                    logger.warning(f"       ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†: {fallback_price} @ {fallback_time}")
                    
                    return {
                        'exit_price': fallback_price,
                        'actual_exit_time': fallback_time,
                        'exit_reason': 'ERROR_FALLBACK',
                        'max_favorable_pips': 0,
                        'max_adverse_pips': 0
                    }
            except Exception as fallback_error:
                logger.error(f"       ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚‚ã‚¨ãƒ©ãƒ¼: {fallback_error}")
            
            return None
            
    def inspect_zip_file_structure(self, zip_path):
        """ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹é€ ã‚’è©³ç´°èª¿æŸ»"""
        logger.info(f"ğŸ” ZIPãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ èª¿æŸ»: {zip_path.name}")
        
        try:
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                file_list = zip_ref.namelist()
                logger.info(f"   ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(file_list)}")
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’è¡¨ç¤ºï¼ˆæœ€åˆã®10ä»¶ï¼‰
                for i, file_name in enumerate(file_list[:10]):
                    logger.info(f"   {i+1:2d}. {file_name}")
                
                if len(file_list) > 10:
                    logger.info(f"   ... ä»– {len(file_list) - 10} ãƒ•ã‚¡ã‚¤ãƒ«")
                
                # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’æŠ½å‡º
                csv_files = [f for f in file_list if f.lower().endswith('.csv')]
                logger.info(f"   CSVãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(csv_files)}")
                
                if csv_files:
                    # æœ€åˆã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°ã‚’èª¿æŸ»
                    test_csv = csv_files[0]
                    logger.info(f"   ãƒ†ã‚¹ãƒˆCSV: {test_csv}")
                    
                    with zip_ref.open(test_csv) as csv_file:
                        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
                        raw_data = csv_file.read()
                        file_size = len(raw_data)
                        logger.info(f"   ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size:,} bytes")
                        
                        if file_size == 0:
                            logger.error("   âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ0ã§ã™")
                            return None
                        
                        # å…ˆé ­ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ãƒ³ãƒ—ï¼ˆæœ€åˆã®500æ–‡å­—ï¼‰
                        preview_data = raw_data[:500]
                        logger.info(f"   ãƒ•ã‚¡ã‚¤ãƒ«å…ˆé ­ãƒ‡ãƒ¼ã‚¿ï¼ˆ500æ–‡å­—ï¼‰:")
                        
                        # è¤‡æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§è©¦è¡Œ
                        for encoding in ['utf-8', 'shift_jis', 'cp932', 'iso-8859-1']:
                            try:
                                decoded = preview_data.decode(encoding)
                                logger.info(f"   ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° {encoding}:")
                                lines = decoded.split('\n')[:5]
                                for j, line in enumerate(lines, 1):
                                    logger.info(f"     {j}: {repr(line)}")
                                break
                            except UnicodeDecodeError:
                                continue
                        
                        return test_csv
                else:
                    logger.error("   âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    return None
                    
        except Exception as e:
            logger.error(f"   âŒ ZIPãƒ•ã‚¡ã‚¤ãƒ«èª¿æŸ»ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def load_entrypoint_files(self):
        """ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
        logger.info("ğŸ“ ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
        
        files = list(ENTRYPOINT_DIR.glob("entrypoints_*.csv"))
        # files = list(ENTRYPOINT_DIR.glob("ã‚ˆãã°ã‚Šã‚¨ãƒ³ãƒˆãƒªãƒ¼_*.csv"))
        files.sort(key=lambda x: x.name)
        
        self.entrypoint_files = []
        
        for file_path in files:
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡º
                date_match = re.search(r'entrypoints_(\d{8})\.csv', file_path.name)
                # date_match = re.search(r'ã‚ˆãã°ã‚Šã‚¨ãƒ³ãƒˆãƒªãƒ¼_(\d{8})\.csv', file_path.name)
                if date_match:
                    date_str = date_match.group(1)
                    date_obj = datetime.strptime(date_str, '%Y%m%d')
                    
                    # CSVèª­ã¿è¾¼ã¿ï¼ˆè¤‡æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¯¾å¿œï¼‰
                    df = self.read_csv_with_encoding(file_path)
                    if df is not None and not df.empty:
                        self.entrypoint_files.append({
                            'date': date_obj,
                            'date_str': date_str,
                            'file_path': file_path,
                            'data': df
                        })
                        
                        logger.info(f"  âœ… {file_path.name}: {len(df)}ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ")
                    else:
                        logger.warning(f"  âŒ {file_path.name}: èª­ã¿è¾¼ã¿å¤±æ•—ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ãªã—")
                    
            except Exception as e:
                logger.error(f"  âŒ {file_path.name}: èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ - {e}")
        
        logger.info(f"ğŸ“Š ç·è¨ˆ {len(self.entrypoint_files)} ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
        
        # æœ€åˆã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹é€ ã‚’è¡¨ç¤º
        if self.entrypoint_files:
            sample_df = self.entrypoint_files[0]['data']
            logger.info(f"ğŸ“ ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã‚µãƒ³ãƒ—ãƒ«:")
            logger.info(f"   ã‚«ãƒ©ãƒ : {list(sample_df.columns)}")
            logger.info(f"   æœ€åˆã®è¡Œ:")
            for col in sample_df.columns:
                logger.info(f"     {col}: {sample_df.iloc[0][col]}")
    
    def read_csv_with_encoding(self, file_path):
        """è¤‡æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§CSVèª­ã¿è¾¼ã¿"""
        encodings = ['utf-8', 'utf-8-sig', 'shift_jis', 'cp932', 'euc_jp', 'iso-8859-1']
        
        for encoding in encodings:
            try:
                df = pd.read_csv(file_path, encoding=encoding)
                if not df.empty and len(df.columns) > 1:
                    logger.debug(f"    ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æˆåŠŸ: {encoding}")
                    return df
            except Exception:
                continue
        
        # chardetã‚’ä½¿ç”¨ã—ãŸæ–‡å­—ã‚³ãƒ¼ãƒ‰è‡ªå‹•åˆ¤å®šï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        if CHARDET_AVAILABLE:
            try:
                with open(file_path, 'rb') as f:
                    raw_data = f.read()
                    detected = chardet.detect(raw_data)
                    encoding = detected['encoding']
                    if encoding:
                        df = pd.read_csv(file_path, encoding=encoding)
                        if not df.empty and len(df.columns) > 1:
                            logger.debug(f"    æ–‡å­—ã‚³ãƒ¼ãƒ‰è‡ªå‹•åˆ¤å®šæˆåŠŸ: {encoding}")
                            return df
            except Exception:
                pass
        
        logger.error(f"    å…¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¤±æ•—: {file_path}")
        return None
    
    def find_historical_data_file(self, currency_pair, date_obj):
        """æŒ‡å®šæ—¥ä»˜ã®éå»ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆï¼‰"""
        try:
            # é€šè²¨ãƒšã‚¢åã‚’çµ±ä¸€ï¼ˆã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ãªã—ï¼‰
            clean_currency = currency_pair.replace('_', '')
            
            # å¹´æœˆã‚’å–å¾—
            year_month = date_obj.strftime('%Y%m')
            
            logger.debug(f"ğŸ” éå»ãƒ‡ãƒ¼ã‚¿æ¤œç´¢: {clean_currency} {year_month}")
            
            # ZIPãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½œæˆï¼ˆã‚ˆã‚Šåºƒç¯„å›²ã«æ¤œç´¢ï¼‰
            zip_patterns = [
                f"{clean_currency}_{year_month}.zip",
                f"{clean_currency.upper()}_{year_month}.zip",
                f"{clean_currency.lower()}_{year_month}.zip"
            ]
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            for pattern in zip_patterns:
                zip_path = HISTORICAL_DATA_DIR / pattern
                if zip_path.exists():
                    logger.info(f"  âœ… éå»ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {pattern}")
                    return zip_path
            
            # è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯å‰å¾Œã®æœˆã‚‚æ¤œç´¢
            for month_offset in [-1, 1, -2, 2]:
                try:
                    target_date = date_obj + timedelta(days=month_offset * 30)
                    alt_year_month = target_date.strftime('%Y%m')
                    
                    for pattern_base in [clean_currency, clean_currency.upper(), clean_currency.lower()]:
                        alt_pattern = f"{pattern_base}_{alt_year_month}.zip"
                        alt_zip_path = HISTORICAL_DATA_DIR / alt_pattern
                        if alt_zip_path.exists():
                            logger.warning(f"  âš ï¸  ä»£æ›¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨: {alt_pattern}")
                            return alt_zip_path
                except Exception:
                    continue
            
            # å…¨ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒªã‚¹ãƒˆã—ã¦ç¢ºèª
            all_zips = list(HISTORICAL_DATA_DIR.glob("*.zip"))
            logger.warning(f"  âŒ éå»ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {currency_pair} {year_month}")
            logger.info(f"  ğŸ“‚ åˆ©ç”¨å¯èƒ½ãªZIPãƒ•ã‚¡ã‚¤ãƒ«:")
            for zip_file in all_zips[:10]:  # æœ€åˆã®10ä»¶ã®ã¿è¡¨ç¤º
                logger.info(f"     {zip_file.name}")
            if len(all_zips) > 10:
                logger.info(f"     ... ä»– {len(all_zips) - 10} ãƒ•ã‚¡ã‚¤ãƒ«")
            
            return None
            
        except Exception as e:
            logger.error(f"    éå»ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def safe_csv_read_from_zip(self, zip_path, target_date):
        """ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰CSVã‚’å®‰å…¨ã«èª­ã¿è¾¼ã¿ï¼ˆãƒ‡ãƒãƒƒã‚°å¼·åŒ–ç‰ˆ + 3å±¤æˆ¦ç•¥ãƒ‡ãƒ¼ã‚¿è¿½åŠ ï¼‰"""
        logger.info(f"ğŸ“„ CSVèª­ã¿è¾¼ã¿é–‹å§‹: {zip_path.name}")
        
        try:
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                file_list = zip_ref.namelist()
                
                # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
                csv_files = [f for f in file_list if f.lower().endswith('.csv') and not f.startswith('__MACOSX')]
                
                if not csv_files:
                    logger.error(f"   âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    return None
                
                logger.info(f"   ğŸ“ CSVãƒ•ã‚¡ã‚¤ãƒ«å€™è£œ: {len(csv_files)}ä»¶")
                
                # å¯¾è±¡æ—¥ä»˜ã«æœ€ã‚‚è¿‘ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
                target_date_str = target_date.strftime('%Y%m%d')
                best_file = None
                best_score = float('inf')
                
                for csv_file in csv_files:
                    # æ—¥ä»˜ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å„ªå…ˆ
                    if target_date_str in csv_file:
                        best_file = csv_file
                        best_score = 0
                        break
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡º
                    date_matches = re.findall(r'(\d{8})', csv_file)
                    if date_matches:
                        for date_str in date_matches:
                            try:
                                file_date = datetime.strptime(date_str, '%Y%m%d')
                                diff_days = abs((file_date - target_date).days)
                                if diff_days < best_score:
                                    best_score = diff_days
                                    best_file = csv_file
                            except ValueError:
                                continue
                
                # æ—¥ä»˜ä¸€è‡´ãŒãªã„å ´åˆã¯æœ€åˆã®CSVã‚’ä½¿ç”¨
                if best_file is None:
                    best_file = csv_files[0]
                    logger.warning(f"   âš ï¸  æ—¥ä»˜ä¸€è‡´ãªã—ã€{best_file}ã‚’ä½¿ç”¨")
                else:
                    logger.info(f"   âœ… é¸æŠã•ã‚ŒãŸCSV: {best_file}")
                
                # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
                with zip_ref.open(best_file) as csv_file_obj:
                    # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’èª­ã¿è¾¼ã¿
                    raw_data = csv_file_obj.read()
                    
                    if len(raw_data) == 0:
                        logger.error(f"   âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™: {best_file}")
                        return None
                    
                    logger.info(f"   ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {len(raw_data):,} bytes")
                    
                    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ¤œå‡ºã—ã¦èª­ã¿è¾¼ã¿
                    df = self.decode_and_parse_csv(raw_data, best_file)
                    
                    if df is not None and not df.empty:
                        logger.info(f"   âœ… CSVèª­ã¿è¾¼ã¿æˆåŠŸ: {len(df)}è¡Œ, {len(df.columns)}åˆ—")
                        
                        # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ãƒ­ã‚°å‡ºåŠ›
                        logger.info(f"   ğŸ“‹ ã‚«ãƒ©ãƒ : {list(df.columns)}")
                        if len(df) > 0:
                            logger.info(f"   ğŸ“ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆæœ€åˆã®è¡Œï¼‰:")
                            for col in df.columns[:5]:  # æœ€åˆã®5åˆ—ã®ã¿
                                logger.info(f"     {col}: {df.iloc[0][col]}")
                        
                        # 3å±¤æˆ¦ç•¥ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                        df = self.add_layer_strategy_data(df)
                        
                        return df
                    else:
                        logger.error(f"   âŒ CSVè§£æå¤±æ•—: {best_file}")
                        return None
        
        except Exception as e:
            logger.error(f"   âŒ ZIPãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def add_layer_strategy_data(self, df):
        """3å±¤æˆ¦ç•¥ç”¨ã®ãƒ‡ãƒ¼ã‚¿åˆ—ã‚’è¿½åŠ """
        try:
            logger.info("   ğŸ¯ 3å±¤æˆ¦ç•¥ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ä¸­...")
            
            # 1. spread, true_range, mid_close ã‚’è¨ˆç®—
            if 'close_ask' in df.columns and 'close_bid' in df.columns:
                df['spread'] = df['close_ask'] - df['close_bid']
                df['mid_close'] = (df['close_ask'] + df['close_bid']) / 2
            else:
                logger.warning("   âš ï¸  close_ask/close_bid ã‚«ãƒ©ãƒ ãŒã‚ã‚Šã¾ã›ã‚“")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åˆ©ç”¨å¯èƒ½ãªä¾¡æ ¼ã‚«ãƒ©ãƒ ã‚’ä½¿ç”¨
                price_cols = [col for col in df.columns if any(price in col.lower() for price in ['close', 'price'])]
                if price_cols:
                    df['spread'] = 0.001  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰
                    df['mid_close'] = df[price_cols[0]]
                else:
                    df['spread'] = 0.001
                    df['mid_close'] = 100.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä¾¡æ ¼
            
            if 'high_ask' in df.columns and 'low_bid' in df.columns:
                df['true_range'] = df['high_ask'] - df['low_bid']
            else:
                logger.warning("   âš ï¸  high_ask/low_bid ã‚«ãƒ©ãƒ ãŒã‚ã‚Šã¾ã›ã‚“")
                df['true_range'] = df['spread'] * 2  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            
            # 2. ATR14ã‚’è¨ˆç®—
            df['atr14'] = df['true_range'].rolling(14, min_periods=1).mean()
            
            # 3. MFTæ–¹å‘ãƒ•ãƒ©ã‚°ã‚’è¨ˆç®—ï¼ˆrolling max ã¨ã®æ¯”è¼ƒï¼‰
            # Longãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®š: mid_close > rolling(n).max().shift(1)
            df['dir_5m'] = df['mid_close'] > df['mid_close'].rolling(5, min_periods=1).max().shift(1)
            df['dir_15m'] = df['mid_close'] > df['mid_close'].rolling(15, min_periods=1).max().shift(1)
            df['dir_1h'] = df['mid_close'] > df['mid_close'].rolling(60, min_periods=1).max().shift(1)
            
            # NaNå€¤ã‚’å‰æ–¹è£œå®Œ
            df['dir_5m'] = df['dir_5m'].fillna(method='ffill').fillna(False)
            df['dir_15m'] = df['dir_15m'].fillna(method='ffill').fillna(False)
            df['dir_1h'] = df['dir_1h'].fillna(method='ffill').fillna(False)
            
            # 4. çµ±è¨ˆå€¤ã‚’è¨ˆç®—ï¼ˆå¾Œã§ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ™‚ã«ä½¿ç”¨ï¼‰
            df['spread_q25'] = df['spread'].quantile(0.25)
            df['spread_q50'] = df['spread'].quantile(0.50)
            df['true_range_q75'] = df['true_range'].quantile(0.75)
            
            logger.info(f"   âœ… 3å±¤æˆ¦ç•¥ãƒ‡ãƒ¼ã‚¿è¿½åŠ å®Œäº†")
            logger.info(f"     spreadç¯„å›²: {df['spread'].min():.5f} - {df['spread'].max():.5f}")
            logger.info(f"     true_rangeç¯„å›²: {df['true_range'].min():.5f} - {df['true_range'].max():.5f}")
            logger.info(f"     ATR14å¹³å‡: {df['atr14'].mean():.5f}")
            
            return df
            
        except Exception as e:
            logger.error(f"   âŒ 3å±¤æˆ¦ç•¥ãƒ‡ãƒ¼ã‚¿è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return df
    
    def get_entry_market_conditions(self, df_historical, entry_datetime):
        """ã‚¨ãƒ³ãƒˆãƒªãƒ¼ç›´å‰ã®å¸‚å ´æ¡ä»¶ã‚’å–å¾—"""
        try:
            # ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ™‚åˆ»ã«æœ€ã‚‚è¿‘ã„ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            df_sorted = df_historical.sort_values('timestamp').copy()
            df_sorted['time_diff'] = abs(df_sorted['timestamp'] - pd.to_datetime(entry_datetime))
            closest_idx = df_sorted['time_diff'].idxmin()
            entry_row = df_sorted.loc[closest_idx]
            
            # å¿…è¦ãªå€¤ã‚’æŠ½å‡º
            conditions = {
                'spread': entry_row.get('spread', 0.001),
                'true_range': entry_row.get('true_range', 0.002),
                'atr14': entry_row.get('atr14', 0.001),
                'dir_5m': entry_row.get('dir_5m', False),
                'dir_15m': entry_row.get('dir_15m', False),
                'dir_1h': entry_row.get('dir_1h', False),
                'spread_q25': entry_row.get('spread_q25', 0.0005),
                'spread_q50': entry_row.get('spread_q50', 0.001),
                'true_range_q75': entry_row.get('true_range_q75', 0.003)
            }
            
            logger.debug(f"     å¸‚å ´æ¡ä»¶: spread={conditions['spread']:.5f}, tr={conditions['true_range']:.5f}, atr14={conditions['atr14']:.5f}")
            logger.debug(f"     æ–¹å‘ãƒ•ãƒ©ã‚°: 5m={conditions['dir_5m']}, 15m={conditions['dir_15m']}, 1h={conditions['dir_1h']}")
            
            return conditions
            
        except Exception as e:
            logger.error(f"     å¸‚å ´æ¡ä»¶å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¿”ã™
            return {
                'spread': 0.001, 'true_range': 0.002, 'atr14': 0.001,
                'dir_5m': False, 'dir_15m': False, 'dir_1h': False,
                'spread_q25': 0.0005, 'spread_q50': 0.001, 'true_range_q75': 0.003
            }
    
    def decode_and_parse_csv(self, raw_data, file_name):
        """ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’CSVã¨ã—ã¦è§£æ"""
        logger.debug(f"   ğŸ”¤ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œå‡ºé–‹å§‹: {file_name}")
        
        # chardetã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œå‡ºï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        if CHARDET_AVAILABLE:
            try:
                detected = chardet.detect(raw_data)
                detected_encoding = detected.get('encoding')
                confidence = detected.get('confidence', 0)
                logger.info(f"   ğŸ¯ æ¤œå‡ºã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {detected_encoding} (ä¿¡é ¼åº¦: {confidence:.2f})")
                
                if detected_encoding and confidence > 0.7:
                    encodings = [detected_encoding] + ['utf-8', 'shift_jis', 'cp932', 'iso-8859-1']
                else:
                    encodings = ['utf-8', 'shift_jis', 'cp932', 'iso-8859-1', detected_encoding]
            except Exception:
                encodings = ['utf-8', 'shift_jis', 'cp932', 'iso-8859-1']
        else:
            encodings = ['utf-8', 'shift_jis', 'cp932', 'euc_jp', 'iso-8859-1']
        
        # å„ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§è©¦è¡Œ
        for encoding in encodings:
            if encoding is None:
                continue
                
            try:
                # ãƒ‡ã‚³ãƒ¼ãƒ‰
                csv_content = raw_data.decode(encoding)
                
                # å†…å®¹ã‚’ç¢ºèªï¼ˆç©ºã§ãªã„ã‹ï¼‰
                if not csv_content.strip():
                    logger.warning(f"     ç©ºã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„: {encoding}")
                    continue
                
                # åŒºåˆ‡ã‚Šæ–‡å­—ã‚’æ¤œå‡º
                lines = csv_content.split('\n')
                first_line = lines[0] if lines else ""
                
                # åŒºåˆ‡ã‚Šæ–‡å­—ã®å€™è£œ
                separators = [',', '\t', ';', '|']
                best_sep = ','
                max_columns = 0
                
                for sep in separators:
                    col_count = len(first_line.split(sep))
                    if col_count > max_columns:
                        max_columns = col_count
                        best_sep = sep
                
                logger.debug(f"     ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {encoding}, åŒºåˆ‡ã‚Šæ–‡å­—: '{best_sep}', ã‚«ãƒ©ãƒ æ•°: {max_columns}")
                
                # æœ€ä½é™ã®ã‚«ãƒ©ãƒ æ•°ãƒã‚§ãƒƒã‚¯
                if max_columns < 4:
                    logger.warning(f"     ã‚«ãƒ©ãƒ æ•°ä¸è¶³: {max_columns}")
                    continue
                
                # DataFrameã«å¤‰æ›
                df = pd.read_csv(io.StringIO(csv_content), sep=best_sep)
                
                # ãƒ‡ãƒ¼ã‚¿ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚ŒãŸã‹ãƒã‚§ãƒƒã‚¯
                if df.empty:
                    logger.warning(f"     ç©ºã®DataFrame: {encoding}")
                    continue
                
                if len(df.columns) < 4:
                    logger.warning(f"     ã‚«ãƒ©ãƒ æ•°ä¸è¶³: {len(df.columns)}")
                    continue
                
                # ã‚«ãƒ©ãƒ åã‚’æ¨™æº–åŒ–
                df = self.normalize_columns_improved(df)
                
                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å‡¦ç†
                df = self.process_timestamp_improved(df)
                
                logger.info(f"   âœ… ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æˆåŠŸ: {encoding}")
                return df
                
            except UnicodeDecodeError:
                logger.debug(f"     ãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {encoding}")
                continue
            except Exception as e:
                logger.debug(f"     è§£æã‚¨ãƒ©ãƒ¼ {encoding}: {e}")
                continue
        
        logger.error(f"   âŒ å…¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¤±æ•—: {file_name}")
        return None
    
    def normalize_columns_improved(self, df):
        """ã‚«ãƒ©ãƒ åã‚’æ¨™æº–åŒ–ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        renamed_columns = {}
        
        # ã‚ˆã‚ŠæŸ”è»Ÿãªã‚«ãƒ©ãƒ åãƒãƒƒãƒ”ãƒ³ã‚°
        column_patterns = {
            'timestamp': [
                'æ—¥æ™‚', 'timestamp', 'time', 'æ™‚åˆ»', 'datetime', 'date',
                'Date', 'Time', 'DateTime', 'æ—¶é—´', 'Date/Time'
            ],
            'open_bid': [
                'å§‹å€¤(BID)', 'open_bid', 'bid_open', 'open bid', 'Open BID',
                'BID Open', 'å§‹å€¤BID', 'BIDå§‹å€¤', 'open(bid)', 'Open(BID)'
            ],
            'high_bid': [
                'é«˜å€¤(BID)', 'high_bid', 'bid_high', 'high bid', 'High BID',
                'BID High', 'é«˜å€¤BID', 'BIDé«˜å€¤', 'high(bid)', 'High(BID)'
            ],
            'low_bid': [
                'å®‰å€¤(BID)', 'low_bid', 'bid_low', 'low bid', 'Low BID',
                'BID Low', 'å®‰å€¤BID', 'BIDå®‰å€¤', 'low(bid)', 'Low(BID)'
            ],
            'close_bid': [
                'çµ‚å€¤(BID)', 'close_bid', 'bid_close', 'close bid', 'Close BID',
                'BID Close', 'çµ‚å€¤BID', 'BIDçµ‚å€¤', 'close(bid)', 'Close(BID)'
            ],
            'open_ask': [
                'å§‹å€¤(ASK)', 'open_ask', 'ask_open', 'open ask', 'Open ASK',
                'ASK Open', 'å§‹å€¤ASK', 'ASKå§‹å€¤', 'open(ask)', 'Open(ASK)'
            ],
            'high_ask': [
                'é«˜å€¤(ASK)', 'high_ask', 'ask_high', 'high ask', 'High ASK',
                'ASK High', 'é«˜å€¤ASK', 'ASKé«˜å€¤', 'high(ask)', 'High(ASK)'
            ],
            'low_ask': [
                'å®‰å€¤(ASK)', 'low_ask', 'ask_low', 'low ask', 'Low ASK',
                'ASK Low', 'å®‰å€¤ASK', 'ASKå®‰å€¤', 'low(ask)', 'Low(ASK)'
            ],
            'close_ask': [
                'çµ‚å€¤(ASK)', 'close_ask', 'ask_close', 'close ask', 'Close ASK',
                'ASK Close', 'çµ‚å€¤ASK', 'ASKçµ‚å€¤', 'close(ask)', 'Close(ASK)'
            ]
        }
        
        # å®Œå…¨ä¸€è‡´ã‚’å„ªå…ˆ
        for col in df.columns:
            col_str = str(col).strip()
            found = False
            
            for standard_name, patterns in column_patterns.items():
                if col_str in patterns:
                    renamed_columns[col] = standard_name
                    found = True
                    break
            
            # éƒ¨åˆ†ä¸€è‡´ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹
            if not found:
                col_lower = col_str.lower()
                
                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—é–¢é€£
                if any(keyword in col_lower for keyword in ['æ™‚', 'time', 'date']):
                    renamed_columns[col] = 'timestamp'
                # BIDé–¢é€£
                elif 'bid' in col_lower:
                    if any(keyword in col_lower for keyword in ['å§‹', 'open']):
                        renamed_columns[col] = 'open_bid'
                    elif any(keyword in col_lower for keyword in ['é«˜', 'high']):
                        renamed_columns[col] = 'high_bid'
                    elif any(keyword in col_lower for keyword in ['å®‰', 'low']):
                        renamed_columns[col] = 'low_bid'
                    elif any(keyword in col_lower for keyword in ['çµ‚', 'close']):
                        renamed_columns[col] = 'close_bid'
                # ASKé–¢é€£
                elif 'ask' in col_lower:
                    if any(keyword in col_lower for keyword in ['å§‹', 'open']):
                        renamed_columns[col] = 'open_ask'
                    elif any(keyword in col_lower for keyword in ['é«˜', 'high']):
                        renamed_columns[col] = 'high_ask'
                    elif any(keyword in col_lower for keyword in ['å®‰', 'low']):
                        renamed_columns[col] = 'low_ask'
                    elif any(keyword in col_lower for keyword in ['çµ‚', 'close']):
                        renamed_columns[col] = 'close_ask'
        
        if renamed_columns:
            df = df.rename(columns=renamed_columns)
            logger.debug(f"     ã‚«ãƒ©ãƒ åæ¨™æº–åŒ–: {len(renamed_columns)}å€‹")
            logger.debug(f"     ãƒãƒƒãƒ”ãƒ³ã‚°: {renamed_columns}")
        
        return df
    
    def process_timestamp_improved(self, df):
        """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å‡¦ç†ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        try:
            if 'timestamp' in df.columns:
                # æ—¢ã«datetimeå‹ã®å ´åˆ
                if pd.api.types.is_datetime64_any_dtype(df['timestamp']):
                    logger.debug("     ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ—¢ã«datetimeå‹")
                    return df
                
                # æ–‡å­—åˆ—ã‹ã‚‰datetimeã«å¤‰æ›
                timestamp_formats = [
                    '%Y/%m/%d %H:%M:%S',
                    '%Y-%m-%d %H:%M:%S',
                    '%Y/%m/%d %H:%M',
                    '%Y-%m-%d %H:%M',
                    '%m/%d/%Y %H:%M:%S',
                    '%d/%m/%Y %H:%M:%S',
                    '%Y%m%d %H:%M:%S',
                    '%Y%m%d %H%M%S',
                    '%Y.%m.%d %H:%M:%S',
                    '%d.%m.%Y %H:%M:%S'
                ]
                
                for fmt in timestamp_formats:
                    try:
                        df['timestamp'] = pd.to_datetime(df['timestamp'], format=fmt, errors='coerce')
                        # NaTã§ãªã„ã‚‚ã®ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                        if not df['timestamp'].isna().all():
                            logger.debug(f"     ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å¤‰æ›æˆåŠŸ: {fmt}")
                            return df
                    except Exception:
                        continue
                
                # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè‡ªå‹•æ¤œå‡º
                try:
                    df['timestamp'] = pd.to_datetime(df['timestamp'], infer_datetime_format=True, errors='coerce')
                    if not df['timestamp'].isna().all():
                        logger.debug("     ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è‡ªå‹•å¤‰æ›æˆåŠŸ")
                        return df
                except Exception as e:
                    logger.debug(f"     ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è‡ªå‹•å¤‰æ›å¤±æ•—: {e}")
        
        except Exception as e:
            logger.warning(f"     ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        
        return df
    
    def get_price_at_time_improved(self, df, target_time, direction):
        """æŒ‡å®šæ™‚åˆ»ã®ä¾¡æ ¼ã‚’å–å¾—ï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆï¼‰"""
        try:
            if df.empty:
                logger.warning("     ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
                return None, None
            
            if 'timestamp' not in df.columns:
                logger.warning(f"     ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚«ãƒ©ãƒ ãªã—ã€‚åˆ©ç”¨å¯èƒ½ã‚«ãƒ©ãƒ : {list(df.columns)}")
                return None, None
            
            # æŒ‡å®šæ™‚åˆ»ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢
            target_datetime = pd.to_datetime(target_time)
            logger.debug(f"     ç›®æ¨™æ™‚åˆ»: {target_datetime}")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’æ™‚ç³»åˆ—é †ã«ã‚½ãƒ¼ãƒˆ
            df_sorted = df.sort_values('timestamp').copy()
            
            # ãƒ‡ãƒ¼ã‚¿ã®æ™‚é–“ç¯„å›²ã‚’ãƒ­ã‚°å‡ºåŠ›
            min_time = df_sorted['timestamp'].min()
            max_time = df_sorted['timestamp'].max()
            logger.debug(f"     ãƒ‡ãƒ¼ã‚¿æ™‚é–“ç¯„å›²: {min_time} ï½ {max_time}")
            
            # ç›®æ¨™æ™‚åˆ»ã«æœ€ã‚‚è¿‘ã„ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢
            df_sorted['time_diff'] = abs(df_sorted['timestamp'] - target_datetime)
            closest_idx = df_sorted['time_diff'].idxmin()
            row = df_sorted.loc[closest_idx]
            
            time_diff_seconds = df_sorted.loc[closest_idx, 'time_diff'].total_seconds()
            time_diff_minutes = time_diff_seconds / 60
            
            # æ™‚åˆ»å·®ç•°ã‚’ãƒ­ã‚°å‡ºåŠ›
            if time_diff_minutes > 60:  # 60åˆ†ä»¥ä¸Šé›¢ã‚Œã¦ã„ã‚‹å ´åˆã¯è­¦å‘Š
                logger.warning(f"     æ™‚åˆ»å·®ç•°å¤§: {time_diff_minutes:.1f}åˆ†")
            
            logger.debug(f"     æœ€ã‚‚è¿‘ã„æ™‚åˆ»: {row['timestamp']} (å·®ç•°: {time_diff_minutes:.1f}åˆ†)")
            
            # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼ï¼ˆæ–¹å‘ã«å¿œã˜ã¦BID/ASKï¼‰
            if direction.upper() in ['LONG', 'BUY']:
                price_columns = ['open_ask', 'close_ask', 'high_ask', 'low_ask']
            else:  # SHORT, SELL
                price_columns = ['open_bid', 'close_bid', 'high_bid', 'low_bid']
            
            # åˆ©ç”¨å¯èƒ½ãªä¾¡æ ¼ã‚«ãƒ©ãƒ ã‚’æ¤œç´¢
            entry_price = None
            used_column = None
            
            for col in price_columns:
                if col in row.index and pd.notna(row[col]):
                    try:
                        entry_price = float(row[col])
                        used_column = col
                        logger.debug(f"     ä¾¡æ ¼å–å¾—æˆåŠŸ: {col} = {entry_price}")
                        break
                    except (ValueError, TypeError):
                        continue
            
            # ä¾¡æ ¼ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
            if entry_price is None:
                logger.warning(f"     æŒ‡å®šä¾¡æ ¼ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                
                # æ•°å€¤ã‚«ãƒ©ãƒ ã‚’æ¢ã™
                numeric_columns = []
                for col in row.index:
                    if pd.notna(row[col]):
                        try:
                            value = float(row[col])
                            if 50 <= value <= 300:  # ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆã®ä¸€èˆ¬çš„ãªç¯„å›²
                                numeric_columns.append((col, value))
                        except (ValueError, TypeError):
                            continue
                
                if numeric_columns:
                    # ä¾¡æ ¼ã‚‰ã—ã„å€¤ã‚’å„ªå…ˆ
                    col, value = numeric_columns[0]
                    entry_price = value
                    used_column = col
                    logger.warning(f"     ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¾¡æ ¼ä½¿ç”¨: {col} = {entry_price}")
                else:
                    # æœ€å¾Œã®æ‰‹æ®µï¼šä»»æ„ã®æ•°å€¤ã‚«ãƒ©ãƒ 
                    for col in row.index:
                        if pd.notna(row[col]):
                            try:
                                entry_price = float(row[col])
                                used_column = col
                                logger.warning(f"     ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {col} = {entry_price}")
                                break
                            except (ValueError, TypeError):
                                continue
            
            if entry_price is None:
                logger.error(f"     åˆ©ç”¨å¯èƒ½ãªä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãªã—")
                return None, None
            
            return entry_price, row['timestamp']
            
        except Exception as e:
            logger.error(f"     ä¾¡æ ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return None, None
    
    def find_historical_data_file_improved(self, currency_pair, date_obj):
        """æŒ‡å®šæ—¥ä»˜ã®éå»ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        try:
            # é€šè²¨ãƒšã‚¢åã‚’çµ±ä¸€ï¼ˆã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ãªã—ï¼‰
            clean_currency = currency_pair.replace('_', '')
            
            # å¯¾è±¡æ—¥ä»˜ã®å¹´æœˆã‚’å–å¾—
            target_year_month = date_obj.strftime('%Y%m')
            target_date_str = date_obj.strftime('%Y%m%d')
            
            logger.debug(f"ğŸ” éå»ãƒ‡ãƒ¼ã‚¿æ¤œç´¢: {clean_currency} {target_date_str}")
            
            # åˆ©ç”¨å¯èƒ½ãªZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã™ã¹ã¦å–å¾—
            all_zips = list(HISTORICAL_DATA_DIR.glob("*.zip"))
            matching_zips = []
            
            # é€šè²¨ãƒšã‚¢ãŒä¸€è‡´ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŠ½å‡º
            for zip_file in all_zips:
                zip_name = zip_file.name.upper()
                if clean_currency.upper() in zip_name:
                    # å¹´æœˆãŒä¸€è‡´ã™ã‚‹ã‹ç¢ºèª
                    if target_year_month in zip_name:
                        matching_zips.append((zip_file, 0))  # å®Œå…¨ä¸€è‡´ï¼ˆå„ªå…ˆåº¦0ï¼‰
                        logger.info(f"  âœ… å®Œå…¨ä¸€è‡´: {zip_file.name}")
                    else:
                        # å¹´æœˆãŒè¿‘ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
                        year_months_in_name = re.findall(r'(\d{6})', zip_name)
                        for ym in year_months_in_name:
                            try:
                                file_date = datetime.strptime(ym, '%Y%m')
                                target_date_ym = datetime.strptime(target_year_month, '%Y%m')
                                month_diff = abs((file_date.year - target_date_ym.year) * 12 + (file_date.month - target_date_ym.month))
                                if month_diff <= 2:  # 2ãƒ¶æœˆä»¥å†…ãªã‚‰å€™è£œ
                                    matching_zips.append((zip_file, month_diff + 1))
                                    logger.info(f"  âš ï¸  è¿‘ä¼¼ä¸€è‡´: {zip_file.name} (å·®ç•°: {month_diff}ãƒ¶æœˆ)")
                            except ValueError:
                                continue
            
            if not matching_zips:
                logger.warning(f"  âŒ éå»ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {currency_pair} {target_year_month}")
                return None
            
            # å„ªå…ˆåº¦é †ã«ã‚½ãƒ¼ãƒˆï¼ˆå„ªå…ˆåº¦ãŒä½ã„é †ï¼‰
            matching_zips.sort(key=lambda x: x[1])
            selected_zip = matching_zips[0][0]
            
            logger.info(f"  ğŸ“„ é¸æŠã•ã‚ŒãŸZIPãƒ•ã‚¡ã‚¤ãƒ«: {selected_zip.name}")
            return selected_zip
            
        except Exception as e:
            logger.error(f"    éå»ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def calculate_pips(self, entry_price, exit_price, currency_pair, direction):
        """Pipsè¨ˆç®—ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        try:
            # é€šè²¨ãƒšã‚¢è¨­å®šã‚’å–å¾—
            settings = self.currency_settings.get(currency_pair.replace('_', ''))
            if not settings:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
                if 'JPY' in currency_pair:
                    pip_multiplier = 100
                else:
                    pip_multiplier = 10000
                logger.debug(f"     ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šä½¿ç”¨: {pip_multiplier}")
            else:
                pip_multiplier = settings['pip_multiplier']
            
            # æ–¹å‘ã«å¿œã˜ãŸPipsè¨ˆç®—
            if direction.upper() in ['LONG', 'BUY']:
                pips = (exit_price - entry_price) * pip_multiplier
            else:  # SHORT, SELL
                pips = (entry_price - exit_price) * pip_multiplier
            
            logger.debug(f"     Pipsè¨ˆç®—: {entry_price} -> {exit_price} = {pips:.1f}pips ({direction})")
            return round(pips, 1)
            
        except Exception as e:
            logger.error(f"     Pipsè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0

    def backtest_single_day(self, entry_data: dict) -> list[dict]:
        """
        1 æ—¥åˆ†ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã€å–å¼•çµæœã‚’ãƒªã‚¹ãƒˆã§è¿”ã™ã€‚
        â–¸ æ”¹è¨‚ç‰ˆï¼š3 å±¤æˆ¦ç•¥ã®â€œæ—¥æ¬¡ã—ãã„å€¤â€ã‚’è¨ˆç®—ã—ã¦ decide_layer ã«æ¸¡ã™ã€‚

        Parameters
        ----------
        entry_data : dict
            {
                'date'     : datetime.date,
                'date_str' : 'YYYYMMDD',
                'data'     : DataFrame  # Step-3 ã§æŠ½å‡ºã—ãŸå½“æ—¥ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
            }

        Returns
        -------
        list[dict]
            1 ãƒˆãƒ¬ãƒ¼ãƒ‰ = 1 ãƒ¬ã‚³ãƒ¼ãƒ‰ã®çµæœè¾æ›¸ï¼ˆCSV ä¿å­˜ãƒ»é›†è¨ˆç”¨ï¼‰
        """
        date_obj  = entry_data["date"]
        date_str  = entry_data["date_str"]
        df_entries = entry_data["data"]

        logger.info(f"ğŸ“… ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ: {date_str}ï¼ˆ{len(df_entries)} ã‚¨ãƒ³ãƒˆãƒªãƒ¼ï¼‰")

        daily_results          : list[dict] = []
        processed_currencies   : dict[str, dict] = {}   # {pair_date: {"df": DataFrame, "th": dict}}

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ— : å½“æ—¥ã®å„ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’é †ã«å‡¦ç†
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        for _, entry in df_entries.iterrows():
            try:
                currency_pair  = entry["é€šè²¨ãƒšã‚¢"]
                direction      = entry["æ–¹å‘"].upper()
                entry_time_str = entry["Entry"]
                exit_time_str  = entry["Exit"]

                logger.info(f"  ğŸ’± {currency_pair} {direction} {entry_time_str}-{exit_time_str}")

                # â¶ éå»ãƒ‡ãƒ¼ã‚¿ ZIP ã‚’å–å¾—
                zip_path = self.find_historical_data_file_improved(currency_pair, date_obj)
                if not zip_path:
                    logger.warning("    âŒ éå»ãƒ‡ãƒ¼ã‚¿ãªã—")
                    continue

                # â· ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¢ºèª
                cache_key = f"{currency_pair}_{date_str}"
                if cache_key not in processed_currencies:
                    # åˆã‚¢ã‚¯ã‚»ã‚¹æ™‚ï¼šZIP æ§‹é€ ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€åˆã® 1 å›ã®ã¿ï¼‰
                    if len(processed_currencies) == 0:
                        self.inspect_zip_file_structure(zip_path)

                    # éå»ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆspread / true_range / atr14 åˆ—ãŒå«ã¾ã‚Œã¦ã„ã‚‹ï¼‰
                    df_hist = self.safe_csv_read_from_zip(zip_path, date_obj)
                    if df_hist is None or df_hist.empty:
                        logger.warning("    âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å¤±æ•—")
                        processed_currencies[cache_key] = None
                        continue

                    # ã—ãã„å€¤ã‚’æ—¥æ¬¡è¨ˆç®—
                    th = self._calc_day_thresholds(df_hist)      # {"sp35", "sp40", "tr50", "atr14_median"}
                    processed_currencies[cache_key] = {"df": df_hist, "th": th}
                    logger.info(f"    ğŸ“¦ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜: {cache_key}")
                else:
                    cached = processed_currencies[cache_key]
                    if cached is None:
                        logger.warning("    âŒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç©º")
                        continue
                    df_hist, th = cached["df"], cached["th"]

                # â¸ ã‚¨ãƒ³ãƒˆãƒªãƒ¼ç›´å‰ 1 åˆ†ã®å¸‚å ´æ¡ä»¶ã‚’å–å¾—
                entry_dt   = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]} {entry_time_str}"
                mkt_cond   = self.get_entry_market_conditions(df_hist, entry_dt)  # spread / true_range / dir_5m â€¦

                # ã‚·ãƒ§ãƒ¼ãƒˆã®å ´åˆã¯æ–¹å‘ãƒ•ãƒ©ã‚°ã‚’åè»¢
                dir_5m  = mkt_cond["dir_5m"]
                dir_15m = mkt_cond["dir_15m"]
                dir_1h  = mkt_cond["dir_1h"]
                if direction in ("SHORT", "SELL"):
                    dir_5m, dir_15m, dir_1h = (not dir_5m, not dir_15m, not dir_1h)

                # â¹ 3 å±¤åˆ¤å®š
                # layer = self.decide_layer(
                #     mkt_cond["spread"], mkt_cond["true_range"],
                #     dir_5m, dir_15m, dir_1h,
                #     th["sp35"], th["sp40"], th["tr50"],
                #     mkt_cond["atr14"], th["atr14_median"]
                # )
                layer = self.decide_layer(
                    # mc["spread"], mc["true_range"],
                    mkt_cond["spread"], mkt_cond["true_range"],
                    dir_5m, dir_15m, dir_1h,
                    th["sp30"], th["sp40"], th["tr40"],
                    # mc["atr14"], th["atr14_median"]
                    mkt_cond["atr14"], th["atr14_median"]
                )
                # âº å±¤åˆ¥ SL / TP è¨­å®š
                sl_pips, tp_pips = self.get_layer_sl_tp(layer, mkt_cond["atr14"])
                original_sl, original_tp = self.stop_loss_pips, self.take_profit_pips
                self.stop_loss_pips, self.take_profit_pips = sl_pips, tp_pips
                logger.info(f"    ğŸ¯ å±¤={layer}  SL={sl_pips}  TP={tp_pips}")

                # â» ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼å–å¾—
                entry_price, actual_entry_time = self.get_price_at_time_improved(
                    df_hist, entry_dt, direction
                )
                if entry_price is None:
                    logger.warning("    âŒ ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼å–å¾—å¤±æ•—")
                    self.stop_loss_pips, self.take_profit_pips = original_sl, original_tp
                    continue

                # â¼ ã‚¨ã‚°ã‚¸ãƒƒãƒˆç›£è¦–
                exit_dt = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]} {exit_time_str}"
                exit_res = self.monitor_position_with_stop_loss(
                    df_hist, entry_dt, exit_dt, entry_price, direction, currency_pair
                )

                self.stop_loss_pips, self.take_profit_pips = original_sl, original_tp
                if exit_res is None:
                    logger.warning("    âŒ ã‚¨ã‚°ã‚¸ãƒƒãƒˆç›£è¦–å¤±æ•—")
                    continue

                # â½ çµæœé›†è¨ˆ
                exit_price        = exit_res["exit_price"]
                pips              = self.calculate_pips(entry_price, exit_price, currency_pair, direction)
                result_flag       = "WIN" if pips > 0 else "LOSS" if pips < 0 else "EVEN"

                trade_result = {
                    "date"              : date_str,
                    "currency_pair"     : currency_pair,
                    "direction"         : direction,
                    "entry_time"        : entry_time_str,
                    "exit_time"         : exit_time_str,
                    "actual_entry_time" : actual_entry_time,
                    "actual_exit_time"  : exit_res["actual_exit_time"],
                    "entry_price"       : entry_price,
                    "exit_price"        : exit_price,
                    "pips"              : pips,
                    "result"            : result_flag,
                    "exit_reason"       : exit_res["exit_reason"],
                    "max_favorable_pips": exit_res["max_favorable_pips"],
                    "max_adverse_pips"  : exit_res["max_adverse_pips"],
                    "layer"             : layer,
                    "sl_pips"           : sl_pips,
                    "tp_pips"           : tp_pips,
                    "score"             : entry.get("å®Ÿç”¨ã‚¹ã‚³ã‚¢", 0.0),
                    "short_win_rate"    : entry.get("çŸ­æœŸå‹ç‡", 0.0),
                    "mid_win_rate"      : entry.get("ä¸­æœŸå‹ç‡", 0.0),
                    "long_win_rate"     : entry.get("é•·æœŸå‹ç‡", 0.0),
                }
                daily_results.append(trade_result)

                status = "ğŸ¯" if exit_res["exit_reason"] == "TAKE_PROFIT" else \
                         "ğŸ›‘" if exit_res["exit_reason"] == "STOP_LOSS"   else "â°"
                logger.info(f"    âœ… {status} {currency_pair} {direction} [{layer}] {pips:.1f}pips ({result_flag})")

            except Exception as e:   # noqa: BLE001
                logger.error(f"    âŒ å–å¼•åˆ†æã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                continue

        logger.info(f"  âœ… æ—¥æ¬¡å®Œäº†: {len(daily_results)}ä»¶")
        return daily_results

    
    def run_backtest(self):
        """ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆã‚¨ãƒ©ãƒ¼è€æ€§å¼·åŒ–ç‰ˆ + 3å±¤æˆ¦ç•¥é›†è¨ˆï¼‰"""
        logger.info("=" * 80)
        logger.info("ğŸš€ FXãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆé–‹å§‹ï¼ˆã‚¨ãƒ©ãƒ¼è€æ€§å¼·åŒ–ç‰ˆ + 3å±¤æˆ¦ç•¥ï¼‰")
        
        try:
            # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            self.load_entrypoint_files()
            
            if not self.entrypoint_files:
                logger.error("âŒ ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
                return
            
            # åˆ©ç”¨å¯èƒ½ãªéå»ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
            logger.info("ğŸ“‚ åˆ©ç”¨å¯èƒ½ãªéå»ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªä¸­...")
            all_zips = list(HISTORICAL_DATA_DIR.glob("*.zip"))
            logger.info(f"   ç·ZIPãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(all_zips)}")
            
            if not all_zips:
                logger.error(f"âŒ éå»ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {HISTORICAL_DATA_DIR}")
                logger.info("ğŸ’¡ ãƒ’ãƒ³ãƒˆ:")
                logger.info("   1. inputãƒ•ã‚©ãƒ«ãƒ€ã«é€šè²¨ãƒšã‚¢ã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã—ã¦ãã ã•ã„")
                logger.info("   2. ãƒ•ã‚¡ã‚¤ãƒ«åã¯ 'USDJPY_YYYYMM.zip' å½¢å¼ã«ã—ã¦ãã ã•ã„")
                return
            
            # å„æ—¥ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
            logger.info("=" * 60)
            logger.info("ğŸ”„ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œé–‹å§‹")
            
            all_results = []
            successful_days = 0
            total_trades = 0
            error_count = 0
            
            for i, entry_data in enumerate(self.entrypoint_files, 1):
                try:
                    logger.info(f"ğŸ“Š é€²æ—: {i}/{len(self.entrypoint_files)} ({i/len(self.entrypoint_files)*100:.1f}%)")
                    
                    daily_results = self.backtest_single_day(entry_data)
                    
                    if daily_results:
                        all_results.extend(daily_results)
                        successful_days += 1
                        total_trades += len(daily_results)
                        logger.info(f"   ğŸ“ˆ ç´¯è¨ˆå–å¼•æ•°: {total_trades}")
                    else:
                        logger.warning(f"   âš ï¸  {entry_data['date_str']}: åˆ†æå¯èƒ½ãªå–å¼•ãªã—")
                        
                except Exception as day_error:
                    error_count += 1
                    logger.error(f"   âŒ {entry_data['date_str']}: ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼ - {day_error}")
                    if error_count > len(self.entrypoint_files) * 0.5:  # ã‚¨ãƒ©ãƒ¼ç‡ãŒ50%ã‚’è¶…ãˆãŸå ´åˆ
                        logger.error("âŒ ã‚¨ãƒ©ãƒ¼ç‡ãŒé«˜ã™ãã¾ã™ã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™")
                        break
                    continue
            
            self.backtest_results = all_results
            
            # çµæœã‚µãƒãƒªãƒ¼
            logger.info("=" * 80)
            logger.info("ğŸ“ˆ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
            logger.info(f"  å‡¦ç†æ—¥æ•°: {len(self.entrypoint_files)}æ—¥")
            logger.info(f"  æˆåŠŸæ—¥æ•°: {successful_days}æ—¥")
            logger.info(f"  ã‚¨ãƒ©ãƒ¼æ—¥æ•°: {error_count}æ—¥")
            logger.info(f"  ç·å–å¼•æ•°: {total_trades}ä»¶")
            
            if total_trades > 0:
                wins = len([r for r in all_results if r['result'] == 'WIN'])
                losses = len([r for r in all_results if r['result'] == 'LOSS'])
                evens = len([r for r in all_results if r['result'] == 'EVEN'])
                win_rate = wins / total_trades * 100
                total_pips = sum(r['pips'] for r in all_results)
                avg_pips = total_pips / total_trades
                
                logger.info(f"  å‹ç‡: {win_rate:.1f}% ({wins}å‹ {losses}æ•— {evens}åˆ†)")
                logger.info(f"  ç·Pips: {total_pips:.1f}")
                logger.info(f"  å¹³å‡Pips/å–å¼•: {avg_pips:.1f}")
                
                # ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹çµ±è¨ˆ
                if self.stop_loss_pips:
                    stop_loss_hits = len([r for r in all_results if r.get('exit_reason') == 'STOP_LOSS'])
                    take_profit_hits = len([r for r in all_results if r.get('exit_reason') == 'TAKE_PROFIT'])
                    time_exits = len([r for r in all_results if r.get('exit_reason') == 'TIME_EXIT'])
                    
                    logger.info(f"  ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ç™ºå‹•: {stop_loss_hits}å› ({stop_loss_hits/total_trades*100:.1f}%)")
                    logger.info(f"  ãƒ†ã‚¤ã‚¯ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆç™ºå‹•: {take_profit_hits}å› ({take_profit_hits/total_trades*100:.1f}%)")
                    logger.info(f"  æ™‚é–“åˆ‡ã‚Œ: {time_exits}å› ({time_exits/total_trades*100:.1f}%)")
                
                # 3å±¤æˆ¦ç•¥åˆ¥é›†è¨ˆã‚’è¡¨ç¤º
                self.display_layer_summary(all_results)
                
                # çµæœã‚’ä¿å­˜
                self.save_results()
                self.calculate_statistics()
                self.generate_report()
            else:
                logger.warning("âš ï¸  åˆ†æå¯èƒ½ãªå–å¼•ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                logger.info("ğŸ’¡ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°:")
                logger.info("   1. ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
                logger.info("   2. éå»ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã¨å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
                logger.info("   3. é€šè²¨ãƒšã‚¢åã®è¡¨è¨˜ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
            
            logger.info("ğŸ‰ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            
            logger.info("ğŸ’¡ ã‚¨ãƒ©ãƒ¼å¯¾å‡¦æ³•:")
            logger.info("   1. ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã§è©³ç´°ãªã‚¨ãƒ©ãƒ¼å†…å®¹ã‚’ç¢ºèª")
            logger.info("   2. ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ç ´æãƒã‚§ãƒƒã‚¯")
            logger.info("   3. ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã¨ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç¢ºèª")
    
    def display_layer_summary(self, all_results):
        """3å±¤æˆ¦ç•¥åˆ¥ã®æˆç¸¾é›†è¨ˆã‚’è¡¨ç¤º"""
        try:
            logger.info("=" * 60)
            logger.info("ğŸ¯ 3å±¤æˆ¦ç•¥åˆ¥æˆç¸¾ã‚µãƒãƒªãƒ¼")
            
            df_results = pd.DataFrame(all_results)
            
            if 'layer' not in df_results.columns:
                logger.warning("âš ï¸  å±¤æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return
            
            # å±¤åˆ¥é›†è¨ˆ
            layer_summary = df_results.groupby('layer').agg({
                'pips': ['count', 'sum', 'mean'],
                'result': lambda x: (x == 'WIN').sum()  # å‹åˆ©æ•°
            }).round(2)
            
            # ãƒ—ãƒ­ãƒ•ã‚£ãƒƒãƒˆãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼è¨ˆç®—
            layer_pf = {}
            for layer in df_results['layer'].unique():
                layer_data = df_results[df_results['layer'] == layer]
                wins_pips = layer_data[layer_data['pips'] > 0]['pips'].sum()
                loss_pips = abs(layer_data[layer_data['pips'] < 0]['pips'].sum())
                
                if loss_pips > 0:
                    profit_factor = wins_pips / loss_pips
                else:
                    profit_factor = wins_pips if wins_pips > 0 else 0
                
                layer_pf[layer] = profit_factor
            
            # ã‚¿ãƒ¼ãƒŸãƒŠãƒ«å‡ºåŠ›
            print("\n" + "=" * 60)
            print("====== SUMMARY by LAYER ======")
            print(f"{'layer':<8} {'trades':<8} {'net_pips':<10} {'avg_pips':<10} {'profit_factor':<15}")
            print("-" * 60)
            
            for layer in ['BASE', 'EXPAND', 'ATR']:
                if layer in layer_summary.index:
                    trades = int(layer_summary.loc[layer, ('pips', 'count')])
                    net_pips = int(layer_summary.loc[layer, ('pips', 'sum')])
                    avg_pips = layer_summary.loc[layer, ('pips', 'mean')]
                    profit_factor = layer_pf.get(layer, 0)
                    
                    print(f"{layer:<8} {trades:<8} {net_pips:<10} {avg_pips:<10.2f} {profit_factor:<15.2f}")
                else:
                    print(f"{layer:<8} {'0':<8} {'0':<10} {'0.00':<10} {'0.00':<15}")
            
            print("=" * 60)
            
            # ãƒ­ã‚°ã«ã‚‚å‡ºåŠ›
            logger.info("ğŸ¯ å±¤åˆ¥è©³ç´°çµ±è¨ˆ:")
            for layer in ['BASE', 'EXPAND', 'ATR']:
                if layer in layer_summary.index:
                    trades = int(layer_summary.loc[layer, ('pips', 'count')])
                    net_pips = int(layer_summary.loc[layer, ('pips', 'sum')])
                    avg_pips = layer_summary.loc[layer, ('pips', 'mean')]
                    wins = int(layer_summary.loc[layer, ('result', '<lambda>')])
                    win_rate = (wins / trades * 100) if trades > 0 else 0
                    profit_factor = layer_pf.get(layer, 0)
                    
                    logger.info(f"  {layer}: {trades}å–å¼•, {net_pips:.0f}pips, å‹ç‡{win_rate:.1f}%, PF{profit_factor:.2f}")
                else:
                    logger.info(f"  {layer}: 0å–å¼•")
                    
        except Exception as e:
            logger.error(f"âŒ å±¤åˆ¥é›†è¨ˆã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
                
    def save_results(self):
        """çµæœã‚’CSVã«ä¿å­˜"""
        if not self.backtest_results:
            logger.warning("ä¿å­˜ã™ã‚‹çµæœãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        try:
            df_results = pd.DataFrame(self.backtest_results)
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è¿½åŠ 
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_file = BACKTEST_RESULT_DIR / f"backtest_results_complete_{timestamp}.csv"
            
            df_results.to_csv(output_file, index=False, encoding='utf-8-sig')
            logger.info(f"âœ… çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file}")
            
        except Exception as e:
            logger.error(f"âŒ çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def calculate_statistics(self):
        """çµ±è¨ˆè¨ˆç®—ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        if not self.backtest_results:
            return
        
        df = pd.DataFrame(self.backtest_results)
        
        # åŸºæœ¬çµ±è¨ˆ
        total_trades = len(df)
        wins = len(df[df['result'] == 'WIN'])
        losses = len(df[df['result'] == 'LOSS'])
        evens = len(df[df['result'] == 'EVEN'])
        
        win_rate = (wins / total_trades * 100) if total_trades > 0 else 0
        
        total_pips = df['pips'].sum()
        avg_pips_per_trade = df['pips'].mean()
        
        max_win = df[df['result'] == 'WIN']['pips'].max() if wins > 0 else 0
        max_loss = df[df['result'] == 'LOSS']['pips'].min() if losses > 0 else 0
        
        # é€£ç¶šå‹æ•—ã®è¨ˆç®—
        consecutive_wins = self.calculate_consecutive_streak(df, 'WIN')
        consecutive_losses = self.calculate_consecutive_streak(df, 'LOSS')
        
        # é€šè²¨ãƒšã‚¢åˆ¥çµ±è¨ˆ
        currency_stats = df.groupby('currency_pair').agg({
            'pips': ['count', 'sum', 'mean'],
            'result': lambda x: (x == 'WIN').sum() / len(x) * 100
        }).round(2)
        
        # æ–¹å‘åˆ¥çµ±è¨ˆ
        direction_stats = df.groupby('direction').agg({
            'pips': ['count', 'sum', 'mean'],
            'result': lambda x: (x == 'WIN').sum() / len(x) * 100
        }).round(2)
        
        # å±¤åˆ¥çµ±è¨ˆ
        layer_stats = df.groupby('layer').agg({
            'pips': ['count', 'sum', 'mean'],
            'result': lambda x: (x == 'WIN').sum() / len(x) * 100
        }).round(2) if 'layer' in df.columns else pd.DataFrame()
        
        # ãƒªã‚¹ã‚¯æŒ‡æ¨™
        daily_pips = df.groupby('date')['pips'].sum()
        max_daily_gain = daily_pips.max() if not daily_pips.empty else 0
        max_daily_loss = daily_pips.min() if not daily_pips.empty else 0
        volatility = daily_pips.std() if len(daily_pips) > 1 else 0
        
        # ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªï¼ˆç°¡æ˜“ç‰ˆï¼‰
        sharpe_ratio = (avg_pips_per_trade / volatility) if volatility > 0 else 0
        
        self.summary_stats = {
            'total_trades': total_trades,
            'wins': wins,
            'losses': losses,
            'evens': evens,
            'win_rate': win_rate,
            'total_pips': total_pips,
            'avg_pips_per_trade': avg_pips_per_trade,
            'max_win': max_win,
            'max_loss': max_loss,
            'consecutive_wins': consecutive_wins,
            'consecutive_losses': consecutive_losses,
            'max_daily_gain': max_daily_gain,
            'max_daily_loss': max_daily_loss,
            'volatility': volatility,
            'sharpe_ratio': sharpe_ratio,
            'currency_stats': currency_stats,
            'direction_stats': direction_stats,
            'layer_stats': layer_stats,
            'test_period': f"{self.entrypoint_files[0]['date_str']} - {self.entrypoint_files[-1]['date_str']}"
        }
        
        logger.info("âœ… çµ±è¨ˆè¨ˆç®—å®Œäº†")
    
    def calculate_consecutive_streak(self, df, result_type):
        """é€£ç¶šå‹æ•—ã®è¨ˆç®—"""
        results = df.sort_values(['date', 'entry_time'])['result'].values
        max_streak = 0
        current_streak = 0
        
        for result in results:
            if result == result_type:
                current_streak += 1
                max_streak = max(max_streak, current_streak)
            else:
                current_streak = 0
        
        return max_streak
    
    def generate_report(self):
        """ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        if not self.backtest_results or not self.summary_stats:
            logger.warning("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        try:
            # HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            self.generate_html_report()
            
            # ã‚°ãƒ©ãƒ•ç”Ÿæˆ
            self.generate_charts()
            
            logger.info("âœ… ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†")
            
        except Exception as e:
            logger.error(f"âŒ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
    
    def generate_html_report(self):
        """HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆå®Œå…¨ç‰ˆ + 3å±¤æˆ¦ç•¥ï¼‰"""
        stats = self.summary_stats
        
        html_content = f"""
        <!DOCTYPE html>
        <html lang="ja">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>FXãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœãƒ¬ãƒãƒ¼ãƒˆï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆ + 3å±¤æˆ¦ç•¥ï¼‰</title>
            <style>
                body {{ font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; margin: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); }}
                .container {{ max-width: 1400px; margin: 0 auto; background-color: white; padding: 30px; border-radius: 15px; box-shadow: 0 0 30px rgba(0,0,0,0.2); }}
                h1 {{ color: #2c3e50; text-align: center; font-size: 2.5em; margin-bottom: 30px; border-bottom: 3px solid #3498db; padding-bottom: 15px; }}
                h2 {{ color: #34495e; border-bottom: 2px solid #3498db; padding-bottom: 10px; margin-top: 40px; }}
                .summary {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin-bottom: 40px; }}
                .stat-card {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 25px; border-radius: 15px; text-align: center; box-shadow: 0 5px 15px rgba(0,0,0,0.1); }}
                .stat-value {{ font-size: 2.2em; font-weight: bold; margin-bottom: 5px; }}
                .stat-label {{ font-size: 1em; opacity: 0.9; }}
                .highlight {{ background: linear-gradient(135deg, #ff7b7b 0%, #ff416c 100%); }}
                .success {{ background: linear-gradient(135deg, #6a11cb 0%, #2575fc 100%); }}
                .layer-success {{ background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%); }}
                table {{ border-collapse: collapse; width: 100%; margin-bottom: 30px; border-radius: 10px; overflow: hidden; box-shadow: 0 0 20px rgba(0,0,0,0.1); }}
                th, td {{ text-align: left; padding: 15px; border: none; }}
                th {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; font-weight: bold; }}
                tr:nth-child(even) {{ background-color: #f8f9fa; }}
                tr:hover {{ background-color: #e3f2fd; }}
                .positive {{ color: #27ae60; font-weight: bold; }}
                .negative {{ color: #e74c3c; font-weight: bold; }}
                .neutral {{ color: #7f8c8d; }}
                .chart-container {{ text-align: center; margin: 30px 0; }}
                .risk-metrics {{ background: linear-gradient(135deg, #ffecd2 0%, #fcb69f 100%); padding: 20px; border-radius: 10px; margin: 20px 0; }}
                .layer-metrics {{ background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%); padding: 20px; border-radius: 10px; margin: 20px 0; }}
                .footer {{ text-align: center; margin-top: 50px; color: #7f8c8d; font-style: italic; }}
            </style>
        </head>
        <body>

            <div class="container">
                <h1>ğŸ“Š FXãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœãƒ¬ãƒãƒ¼ãƒˆï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆ + 3å±¤æˆ¦ç•¥ï¼‰</h1>
                
                <div class="summary">
                    <div class="stat-card success">
                        <div class="stat-value">{stats['total_trades']}</div>
                        <div class="stat-label">ç·å–å¼•æ•°</div>
                    </div>
                    <div class="stat-card {'success' if stats['win_rate'] >= 60 else 'highlight' if stats['win_rate'] >= 50 else ''}">
                        <div class="stat-value">{stats['win_rate']:.1f}%</div>
                        <div class="stat-label">å‹ç‡</div>
                    </div>
                    <div class="stat-card {'success' if stats['total_pips'] > 0 else 'highlight'}">
                        <div class="stat-value">{stats['total_pips']:.1f}</div>
                        <div class="stat-label">ç·Pips</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-value">{stats['avg_pips_per_trade']:.1f}</div>
                        <div class="stat-label">å¹³å‡Pips/å–å¼•</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-value">{stats['sharpe_ratio']:.2f}</div>
                        <div class="stat-label">ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª</div>
                    </div>
                </div>
                
                <div class="layer-metrics">
                    <h2>ğŸ¯ 3å±¤æˆ¦ç•¥åˆ¥æˆç¸¾</h2>
                    <table>
                        <tr><th>æˆ¦ç•¥å±¤</th><th>å–å¼•æ•°</th><th>ç·Pips</th><th>å¹³å‡Pips</th><th>å‹ç‡(%)</th></tr>
        """
        
        # 3å±¤æˆ¦ç•¥åˆ¥çµ±è¨ˆã‚’è¿½åŠ 
        if not stats['layer_stats'].empty:
            for layer, stats_row in stats['layer_stats'].iterrows():
                total_pips = stats_row[('pips', 'sum')]
                avg_pips = stats_row[('pips', 'mean')]
                win_rate = stats_row[('result', '<lambda>')]
                count = stats_row[('pips', 'count')]
                
                pips_class = 'positive' if total_pips > 0 else 'negative' if total_pips < 0 else 'neutral'
                
                html_content += f"""
                        <tr>
                            <td><strong>{layer}</strong></td>
                            <td>{count}</td>
                            <td class="{pips_class}">{total_pips:.1f}</td>
                            <td class="{pips_class}">{avg_pips:.1f}</td>
                            <td>{win_rate:.1f}%</td>
                        </tr>
                """
        
        html_content += f"""
                    </table>
                </div>
                
                <div class="risk-metrics">
                    <h2>ğŸ›¡ï¸ ãƒªã‚¹ã‚¯æŒ‡æ¨™</h2>
                    <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px;">
                        <div>æœ€å¤§å‹ã¡: <span class="positive">{stats['max_win']:.1f} pips</span></div>
                        <div>æœ€å¤§è² ã‘: <span class="negative">{stats['max_loss']:.1f} pips</span></div>
                        <div>æœ€å¤§æ—¥æ¬¡åˆ©ç›Š: <span class="positive">{stats['max_daily_gain']:.1f} pips</span></div>
                        <div>æœ€å¤§æ—¥æ¬¡æå¤±: <span class="negative">{stats['max_daily_loss']:.1f} pips</span></div>
                        <div>æœ€å¤§é€£å‹: <span class="positive">{stats['consecutive_wins']}å›</span></div>
                        <div>æœ€å¤§é€£æ•—: <span class="negative">{stats['consecutive_losses']}å›</span></div>
                    </div>
                </div>
                
                <h2>ğŸ“ˆ è©³ç´°çµ±è¨ˆ</h2>
                <table>
                    <tr><th>é …ç›®</th><th>å€¤</th></tr>
                    <tr><td>ãƒ†ã‚¹ãƒˆæœŸé–“</td><td>{stats['test_period']}</td></tr>
                    <tr><td>å‹ã¡</td><td class="positive">{stats['wins']}å›</td></tr>
                    <tr><td>è² ã‘</td><td class="negative">{stats['losses']}å›</td></tr>
                    <tr><td>å¼•ãåˆ†ã‘</td><td class="neutral">{stats['evens']}å›</td></tr>
                    <tr><td>æ—¥æ¬¡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£</td><td>{stats['volatility']:.1f} pips</td></tr>
                </table>
                
                <h2>ğŸ’± é€šè²¨ãƒšã‚¢åˆ¥æˆç¸¾</h2>
                <table>
                    <tr><th>é€šè²¨ãƒšã‚¢</th><th>å–å¼•æ•°</th><th>ç·Pips</th><th>å¹³å‡Pips</th><th>å‹ç‡(%)</th></tr>
        """
        
        # é€šè²¨ãƒšã‚¢åˆ¥çµ±è¨ˆã‚’è¿½åŠ 
        if not stats['currency_stats'].empty:
            for currency, stats_row in stats['currency_stats'].iterrows():
                total_pips = stats_row[('pips', 'sum')]
                avg_pips = stats_row[('pips', 'mean')]
                win_rate = stats_row[('result', '<lambda>')]
                count = stats_row[('pips', 'count')]
                
                pips_class = 'positive' if total_pips > 0 else 'negative' if total_pips < 0 else 'neutral'
                
                html_content += f"""
                        <tr>
                            <td><strong>{currency}</strong></td>
                            <td>{count}</td>
                            <td class="{pips_class}">{total_pips:.1f}</td>
                            <td class="{pips_class}">{avg_pips:.1f}</td>
                            <td>{win_rate:.1f}%</td>
                        </tr>
                """
        
        html_content += """
                </table>
                
                <h2>ğŸ¯ æ–¹å‘åˆ¥æˆç¸¾</h2>
                <table>
                    <tr><th>æ–¹å‘</th><th>å–å¼•æ•°</th><th>ç·Pips</th><th>å¹³å‡Pips</th><th>å‹ç‡(%)</th></tr>
        """
        
        # æ–¹å‘åˆ¥çµ±è¨ˆã‚’è¿½åŠ 
        if not stats['direction_stats'].empty:
            for direction, stats_row in stats['direction_stats'].iterrows():
                total_pips = stats_row[('pips', 'sum')]
                avg_pips = stats_row[('pips', 'mean')]
                win_rate = stats_row[('result', '<lambda>')]
                count = stats_row[('pips', 'count')]
                
                pips_class = 'positive' if total_pips > 0 else 'negative' if total_pips < 0 else 'neutral'
                
                html_content += f"""
                        <tr>
                            <td><strong>{direction}</strong></td>
                            <td>{count}</td>
                            <td class="{pips_class}">{total_pips:.1f}</td>
                            <td class="{pips_class}">{avg_pips:.1f}</td>
                            <td>{win_rate:.1f}%</td>
                        </tr>
                """
        
        html_content += f"""
                </table>
                
                <div class="chart-container">
                    <h2>ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ£ãƒ¼ãƒˆ</h2>
                    <p>è©³ç´°ãªãƒãƒ£ãƒ¼ãƒˆã¯ backtest_charts_complete_*.png ã‚’ã”ç¢ºèªãã ã•ã„</p>
                </div>
                
                <div class="footer">
                    <p>ğŸ“… ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}</p>
                    <p>ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ : FXãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ å®Œå…¨ä¿®æ­£ç‰ˆ + 3å±¤æˆ¦ç•¥</p>
                </div>
            </div>
        </body>
        </html>
        """
        
        # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        html_file = BACKTEST_RESULT_DIR / f"backtest_report_complete_{timestamp}.html"
        
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        logger.info(f"âœ… HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {html_file}")
    
    def generate_charts(self):
        """ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆï¼ˆæ”¹è‰¯ç‰ˆ + 3å±¤æˆ¦ç•¥ï¼‰"""
        if not self.backtest_results:
            return
        
        try:
            # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
            plt.rcParams['font.family'] = 'DejaVu Sans'
            
            df = pd.DataFrame(self.backtest_results)
            
            # å›³ã®ã‚µã‚¤ã‚ºã‚’è¨­å®šï¼ˆ3å±¤æˆ¦ç•¥ç”¨ã«æ‹¡å¼µï¼‰
            fig, axes = plt.subplots(3, 3, figsize=(20, 15))
            fig.suptitle('FX Backtest Performance Analysis (Complete Fixed + 3-Layer Strategy)', fontsize=16, fontweight='bold')
            
            # 1. ç´¯ç©Pipsæ¨ç§»
            df_sorted = df.sort_values(['date', 'entry_time']).reset_index(drop=True)
            df_sorted['cumulative_pips'] = df_sorted['pips'].cumsum()
            df_sorted['trade_number'] = range(1, len(df_sorted) + 1)
            
            axes[0, 0].plot(df_sorted['trade_number'], df_sorted['cumulative_pips'], 
                            linewidth=2.5, color='#2E86AB', alpha=0.8)
            axes[0, 0].fill_between(df_sorted['trade_number'], df_sorted['cumulative_pips'], 
                                    alpha=0.3, color='#2E86AB')
            axes[0, 0].set_title('Cumulative Pips Progress', fontweight='bold', fontsize=12)
            axes[0, 0].set_xlabel('Trade Number')
            axes[0, 0].set_ylabel('Cumulative Pips')
            axes[0, 0].grid(True, alpha=0.3)
            axes[0, 0].axhline(y=0, color='red', linestyle='--', alpha=0.7)
            
            # 2. å‹æ•—åˆ†å¸ƒï¼ˆå††ã‚°ãƒ©ãƒ•ï¼‰
            result_counts = df['result'].value_counts()
            colors = ['#27AE60', '#E74C3C', '#95A5A6']
            axes[0, 1].pie(result_counts.values, labels=result_counts.index, colors=colors, 
                            autopct='%1.1f%%', startangle=90, shadow=True)
            axes[0, 1].set_title('Win/Loss Distribution', fontweight='bold', fontsize=12)
            
            # 3. Pipsåˆ†å¸ƒï¼ˆãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼‰
            axes[0, 2].hist(df['pips'], bins=30, alpha=0.7, color='#F39C12', 
                            edgecolor='black', density=True)
            axes[0, 2].set_title('Pips Distribution', fontweight='bold', fontsize=12)
            axes[0, 2].set_xlabel('Pips')
            axes[0, 2].set_ylabel('Density')
            axes[0, 2].axvline(x=0, color='red', linestyle='--', alpha=0.7)
            axes[0, 2].axvline(x=df['pips'].mean(), color='green', linestyle='-', alpha=0.7, 
                                label=f'Mean: {df["pips"].mean():.1f}')
            axes[0, 2].legend()
            axes[0, 2].grid(True, alpha=0.3)
            
            # 4. é€šè²¨ãƒšã‚¢åˆ¥æˆç¸¾
            currency_pips = df.groupby('currency_pair')['pips'].sum().sort_values(ascending=True)
            colors_curr = ['#E74C3C' if x < 0 else '#27AE60' for x in currency_pips.values]
            
            bars = axes[1, 0].barh(range(len(currency_pips)), currency_pips.values, color=colors_curr)
            axes[1, 0].set_yticks(range(len(currency_pips)))
            axes[1, 0].set_yticklabels(currency_pips.index)
            axes[1, 0].set_title('Total Pips by Currency Pair', fontweight='bold', fontsize=12)
            axes[1, 0].set_xlabel('Total Pips')
            axes[1, 0].axvline(x=0, color='black', linestyle='-', alpha=0.8)
            axes[1, 0].grid(True, alpha=0.3)
            
            # 5. æ–¹å‘åˆ¥æˆç¸¾
            direction_pips = df.groupby('direction')['pips'].sum()
            colors_dir = ['#3498DB', '#9B59B6']
            
            bars2 = axes[1, 1].bar(direction_pips.index, direction_pips.values, color=colors_dir, alpha=0.8)
            axes[1, 1].set_title('Total Pips by Direction', fontweight='bold', fontsize=12)
            axes[1, 1].set_ylabel('Total Pips')
            axes[1, 1].grid(True, alpha=0.3)
            
            # 6. æ—¥åˆ¥æˆç¸¾
            df['date_parsed'] = pd.to_datetime(df['date'], format='%Y%m%d')
            daily_pips = df.groupby('date_parsed')['pips'].sum()
            
            axes[1, 2].plot(daily_pips.index, daily_pips.values, marker='o', linewidth=2, 
                            markersize=6, color='#8E44AD', alpha=0.8)
            axes[1, 2].fill_between(daily_pips.index, daily_pips.values, alpha=0.3, color='#8E44AD')
            axes[1, 2].set_title('Daily Performance', fontweight='bold', fontsize=12)
            axes[1, 2].set_xlabel('Date')
            axes[1, 2].set_ylabel('Daily Pips')
            axes[1, 2].tick_params(axis='x', rotation=45)
            axes[1, 2].grid(True, alpha=0.3)
            axes[1, 2].axhline(y=0, color='red', linestyle='--', alpha=0.7)
            
            # 7. 3å±¤æˆ¦ç•¥åˆ¥æˆç¸¾ï¼ˆæ£’ã‚°ãƒ©ãƒ•ï¼‰
            if 'layer' in df.columns:
                layer_pips = df.groupby('layer')['pips'].sum()
                layer_colors = {'BASE': '#3498DB', 'EXPAND': '#27AE60', 'ATR': '#E67E22'}
                colors_layer = [layer_colors.get(layer, '#95A5A6') for layer in layer_pips.index]
                
                bars3 = axes[2, 0].bar(layer_pips.index, layer_pips.values, color=colors_layer, alpha=0.8)
                axes[2, 0].set_title('Total Pips by Strategy Layer', fontweight='bold', fontsize=12)
                axes[2, 0].set_ylabel('Total Pips')
                axes[2, 0].grid(True, alpha=0.3)
                axes[2, 0].axhline(y=0, color='black', linestyle='-', alpha=0.8)
                
                # 8. 3å±¤æˆ¦ç•¥åˆ¥å–å¼•æ•°ï¼ˆå††ã‚°ãƒ©ãƒ•ï¼‰
                layer_counts = df['layer'].value_counts()
                layer_pie_colors = [layer_colors.get(layer, '#95A5A6') for layer in layer_counts.index]
                
                axes[2, 1].pie(layer_counts.values, labels=layer_counts.index, colors=layer_pie_colors,
                                autopct='%1.1f%%', startangle=90, shadow=True)
                axes[2, 1].set_title('Trade Distribution by Layer', fontweight='bold', fontsize=12)
                
                # 9. 3å±¤æˆ¦ç•¥åˆ¥å‹ç‡
                layer_winrates = df.groupby('layer').apply(lambda x: (x['result'] == 'WIN').sum() / len(x) * 100)
                
                bars4 = axes[2, 2].bar(layer_winrates.index, layer_winrates.values, 
                                        color=[layer_colors.get(layer, '#95A5A6') for layer in layer_winrates.index], 
                                        alpha=0.8)
                axes[2, 2].set_title('Win Rate by Strategy Layer', fontweight='bold', fontsize=12)
                axes[2, 2].set_ylabel('Win Rate (%)')
                axes[2, 2].set_ylim(0, 100)
                axes[2, 2].grid(True, alpha=0.3)
                axes[2, 2].axhline(y=50, color='red', linestyle='--', alpha=0.7, label='Break-even')
                axes[2, 2].legend()
            else:
                # 3å±¤æˆ¦ç•¥ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ç©ºã®ãƒ—ãƒ­ãƒƒãƒˆ
                for i in range(3):
                    axes[2, i].text(0.5, 0.5, 'No Layer Data', ha='center', va='center', transform=axes[2, i].transAxes)
                    axes[2, i].set_title(f'Layer Analysis {i+1}', fontweight='bold', fontsize=12)
            
            # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´
            plt.tight_layout()
            
            # ãƒãƒ£ãƒ¼ãƒˆã‚’ä¿å­˜
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            chart_file = BACKTEST_RESULT_DIR / f"backtest_charts_complete_{timestamp}.png"
            plt.savefig(chart_file, dpi=300, bbox_inches='tight', facecolor='white')
            plt.close()
            
            logger.info(f"âœ… ãƒãƒ£ãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {chart_file}")
            
        except Exception as e:
            logger.error(f"âŒ ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
    
    def print_summary(self):
        """ã‚µãƒãƒªãƒ¼ã‚’ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›ï¼ˆæ”¹è‰¯ç‰ˆ + 3å±¤æˆ¦ç•¥ï¼‰"""
        if not self.summary_stats:
            logger.warning("ã‚µãƒãƒªãƒ¼çµ±è¨ˆãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        stats = self.summary_stats
        
        print("\n" + "=" * 80)
        print("ğŸ“Š FXãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼ï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆ + 3å±¤æˆ¦ç•¥ï¼‰")
        print("=" * 80)
        print(f"ğŸ“… ãƒ†ã‚¹ãƒˆæœŸé–“: {stats['test_period']}")
        print(f"ğŸ“ˆ ç·å–å¼•æ•°: {stats['total_trades']}")
        
        if stats['total_trades'] > 0:
            print(f"ğŸ¯ å‹ç‡: {stats['win_rate']:.1f}% ({stats['wins']}å‹ {stats['losses']}æ•— {stats['evens']}åˆ†)")
            print(f"ğŸ’° ç·Pips: {stats['total_pips']:.1f}")
            print(f"ğŸ“Š å¹³å‡Pips/å–å¼•: {stats['avg_pips_per_trade']:.1f}")
            print(f"ğŸš€ æœ€å¤§å‹ã¡: {stats['max_win']:.1f} pips")
            print(f"ğŸ“‰ æœ€å¤§è² ã‘: {stats['max_loss']:.1f} pips")
            print(f"ğŸ”¥ æœ€å¤§é€£å‹: {stats['consecutive_wins']}å›")
            print(f"â„ï¸  æœ€å¤§é€£æ•—: {stats['consecutive_losses']}å›")
            print(f"ğŸ“ˆ æœ€å¤§æ—¥æ¬¡åˆ©ç›Š: {stats['max_daily_gain']:.1f} pips")
            print(f"ğŸ“‰ æœ€å¤§æ—¥æ¬¡æå¤±: {stats['max_daily_loss']:.1f} pips")
            print(f"ğŸ“Š ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª: {stats['sharpe_ratio']:.2f}")
            
            print("=" * 80)
            
            # 3å±¤æˆ¦ç•¥åˆ¥æˆç¸¾
            if not stats['layer_stats'].empty:
                print("ğŸ¯ 3å±¤æˆ¦ç•¥åˆ¥æˆç¸¾:")
                for layer, row in stats['layer_stats'].iterrows():
                    total_pips = row[('pips', 'sum')]
                    win_rate = row[('result', '<lambda>')]
                    count = row[('pips', 'count')]
                    print(f"  {layer}: {total_pips:.1f}pips (å‹ç‡{win_rate:.1f}%, {count}å›)")
            
            # é€šè²¨ãƒšã‚¢åˆ¥ãƒˆãƒƒãƒ—3
            currency_stats = stats['currency_stats']
            if not currency_stats.empty:
                top_currencies = currency_stats.sort_values(('pips', 'sum'), ascending=False).head(3)
                
                print("\nğŸ† é€šè²¨ãƒšã‚¢åˆ¥æˆç¸¾ TOP3:")
                for i, (currency, row) in enumerate(top_currencies.iterrows(), 1):
                    total_pips = row[('pips', 'sum')]
                    win_rate = row[('result', '<lambda>')]
                    count = row[('pips', 'count')]
                    print(f"  {i}. {currency}: {total_pips:.1f}pips (å‹ç‡{win_rate:.1f}%, {count}å›)")
            
            # æ–¹å‘åˆ¥æˆç¸¾
            direction_stats = stats['direction_stats']
            if not direction_stats.empty:
                print("\nğŸ¯ æ–¹å‘åˆ¥æˆç¸¾:")
                for direction, row in direction_stats.iterrows():
                    total_pips = row[('pips', 'sum')]
                    win_rate = row[('result', '<lambda>')]
                    count = row[('pips', 'count')]
                    print(f"  {direction}: {total_pips:.1f}pips (å‹ç‡{win_rate:.1f}%, {count}å›)")
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
            print("\nğŸ–ï¸  ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡:")
            if stats['win_rate'] >= 70:
                print("  å‹ç‡: â­â­â­ å„ªç§€")
            elif stats['win_rate'] >= 60:
                print("  å‹ç‡: â­â­ è‰¯å¥½")
            elif stats['win_rate'] >= 50:
                print("  å‹ç‡: â­ æ™®é€š")
            else:
                print("  å‹ç‡: âŒ è¦æ”¹å–„")
            
            if stats['total_pips'] > 0:
                print("  ç·åç›Š: âœ… ãƒ—ãƒ©ã‚¹")
            else:
                print("  ç·åç›Š: âŒ ãƒã‚¤ãƒŠã‚¹")
            
            if stats['sharpe_ratio'] > 1.0:
                print("  ãƒªã‚¹ã‚¯èª¿æ•´åç›Š: â­â­â­ å„ªç§€")
            elif stats['sharpe_ratio'] > 0.5:
                print("  ãƒªã‚¹ã‚¯èª¿æ•´åç›Š: â­â­ è‰¯å¥½")
            elif stats['sharpe_ratio'] > 0:
                print("  ãƒªã‚¹ã‚¯èª¿æ•´åç›Š: â­ æ™®é€š")
            else:
                print("  ãƒªã‚¹ã‚¯èª¿æ•´åç›Š: âŒ è¦æ”¹å–„")
                
        else:
            print("âŒ åˆ†æå¯èƒ½ãªå–å¼•ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        
        print("=" * 80)


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        print("ğŸš€ FXãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆå®Œå…¨ä¿®æ­£ç‰ˆ + 3å±¤æˆ¦ç•¥ï¼‰ã‚’é–‹å§‹ã—ã¾ã™...")
        
        # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–
        backtest_system = FXBacktestSystemComplete()
        
        # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        backtest_system.run_backtest()
        
        # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        backtest_system.print_summary()
        
        print(f"\nğŸ“ è©³ç´°ãªçµæœã¯ {BACKTEST_RESULT_DIR} ãƒ•ã‚©ãƒ«ãƒ€ã‚’ã”ç¢ºèªãã ã•ã„")
        print("ğŸ“‹ ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã™:")
        print("  - backtest_results_complete_*.csv : å…¨å–å¼•è©³ç´°ãƒ‡ãƒ¼ã‚¿ï¼ˆå±¤æƒ…å ±ä»˜ãï¼‰")
        print("  - backtest_report_complete_*.html : ç¾ã—ã„HTMLãƒ¬ãƒãƒ¼ãƒˆï¼ˆ3å±¤æˆ¦ç•¥å¯¾å¿œï¼‰")
        print("  - backtest_charts_complete_*.png : ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ£ãƒ¼ãƒˆï¼ˆå±¤åˆ¥åˆ†æä»˜ãï¼‰")
        print("  - backtest_fixed_complete.log : å®Ÿè¡Œãƒ­ã‚°")
        
    except Exception as e:
        logger.error(f"âŒ ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
   main()