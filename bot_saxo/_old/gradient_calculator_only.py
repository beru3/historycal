#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
fx_gradient_calculator.py - FXå‹¾é…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—å°‚ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
éå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰1åˆ†è¶³ãƒ™ãƒ¼ã‚¹ã§4æ™‚é–“è»¸ã®å‹¾é…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨ˆç®—
"""

import pandas as pd
import numpy as np
import os
import glob
import zipfile
import io
import json
from datetime import datetime, timedelta
import logging

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('fx_gradient_calculator.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class FXGradientCalculator:
    """FXå‹¾é…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨ˆç®—ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, input_dir="input"):
        self.input_dir = input_dir
        self.cached_data = {}
        
        # ã‚«ãƒ©ãƒ åã®æ­£è¦åŒ–ãƒãƒƒãƒ”ãƒ³ã‚°
        self.column_mapping = {
            "æ—¥æ™‚": "timestamp",
            "å§‹å€¤(BID)": "open_bid",
            "é«˜å€¤(BID)": "high_bid", 
            "å®‰å€¤(BID)": "low_bid",
            "çµ‚å€¤(BID)": "close_bid",
            "å§‹å€¤(ASK)": "open_ask",
            "é«˜å€¤(ASK)": "high_ask",
            "å®‰å€¤(ASK)": "low_ask", 
            "çµ‚å€¤(ASK)": "close_ask"
        }
    
    def get_available_currency_pairs(self):
        """åˆ©ç”¨å¯èƒ½ãªé€šè²¨ãƒšã‚¢ã‚’å–å¾—"""
        zip_files = glob.glob(os.path.join(self.input_dir, "*.zip"))
        currency_pairs = set()
        
        for zip_file in zip_files:
            filename = os.path.basename(zip_file)
            # USDJPY_202505.zip -> USDJPY
            currency_pair = filename.split('_')[0]
            currency_pairs.add(currency_pair)
        
        return sorted(list(currency_pairs))
    
    def load_recent_data(self, currency_pair, days_back=30):
        """æœ€è¿‘ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆéå»30æ—¥åˆ†ï¼‰"""
        logger.info(f"ğŸ“Š {currency_pair} ã®éå»{days_back}æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        
        # å¯¾è±¡æœŸé–“ã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®š
        today = datetime.now()
        target_months = []
        
        # éå»2ãƒ¶æœˆåˆ†ã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¯¾è±¡
        for month_offset in range(3):  # ä½™è£•ã‚’æŒã£ã¦3ãƒ¶æœˆ
            target_month = today - timedelta(days=30 * month_offset)
            target_months.append(target_month.strftime('%Y%m'))
        
        all_data = []
        
        for year_month in target_months:
            zip_pattern = f"{currency_pair}_{year_month}.zip"
            zip_path = os.path.join(self.input_dir, zip_pattern)
            
            if os.path.exists(zip_path):
                logger.info(f"   ğŸ“ {zip_pattern} ã‚’å‡¦ç†ä¸­...")
                month_data = self._extract_data_from_zip(zip_path)
                all_data.extend(month_data)
        
        if not all_data:
            logger.error(f"âŒ {currency_pair} ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return pd.DataFrame()
        
        # DataFrameã«å¤‰æ›
        df = pd.DataFrame(all_data)
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df = df.sort_values('timestamp').reset_index(drop=True)
        
        # éå»30æ—¥åˆ†ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        cutoff_date = today - timedelta(days=days_back)
        df = df[df['timestamp'] >= cutoff_date]
        
        logger.info(f"âœ… {currency_pair}: {len(df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿å®Œäº†")
        logger.info(f"   æœŸé–“: {df['timestamp'].min()} ï½ {df['timestamp'].max()}")
        
        return df
    
    def _extract_data_from_zip(self, zip_path):
        """ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        data = []
        
        try:
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                csv_files = [f for f in zip_ref.namelist() if f.endswith('.csv')]
                
                for csv_file in csv_files:
                    try:
                        with zip_ref.open(csv_file) as file:
                            # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦è¡Œ
                            for encoding in ['utf-8', 'shift_jis', 'cp932', 'euc_jp']:
                                try:
                                    content = file.read().decode(encoding)
                                    df = pd.read_csv(io.StringIO(content))
                                    
                                    # ã‚«ãƒ©ãƒ åã‚’æ­£è¦åŒ–
                                    df = df.rename(columns=self.column_mapping)
                                    
                                    # å¿…è¦ãªã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                                    required_cols = ['timestamp', 'open_bid', 'high_bid', 'low_bid', 'close_bid', 
                                                   'open_ask', 'high_ask', 'low_ask', 'close_ask']
                                    
                                    if all(col in df.columns for col in required_cols):
                                        # ä¸­é–“ä¾¡æ ¼ã‚’è¨ˆç®—
                                        for _, row in df.iterrows():
                                            data.append({
                                                'timestamp': row['timestamp'],
                                                'open': (row['open_bid'] + row['open_ask']) / 2,
                                                'high': (row['high_bid'] + row['high_ask']) / 2,
                                                'low': (row['low_bid'] + row['low_ask']) / 2,
                                                'close': (row['close_bid'] + row['close_ask']) / 2,
                                                'volume': 1  # ãƒ€ãƒŸãƒ¼å€¤
                                            })
                                        break
                                except UnicodeDecodeError:
                                    continue
                    except Exception as e:
                        logger.warning(f"CSVãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {csv_file} - {e}")
                        continue
        
        except Exception as e:
            logger.error(f"ZIPå‡¦ç†ã‚¨ãƒ©ãƒ¼: {zip_path} - {e}")
        
        return data
    
    def resample_to_timeframes(self, df):
        """1åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã‚’å„æ™‚é–“è»¸ã«ãƒªã‚µãƒ³ãƒ—ãƒ«"""
        if df.empty:
            return {}
        
        df = df.set_index('timestamp')
        
        timeframes = {
            '1min': df.resample('1T'),
            '5min': df.resample('5T'),
            '15min': df.resample('15T'),
            '1hour': df.resample('1H')
        }
        
        resampled = {}
        for tf_name, resampler in timeframes.items():
            resampled[tf_name] = resampler.agg({
                'open': 'first',
                'high': 'max',
                'low': 'min',
                'close': 'last',
                'volume': 'sum'
            }).dropna()
            
            logger.info(f"   {tf_name}: {len(resampled[tf_name])}æœ¬ã®ãƒ­ãƒ¼ã‚½ã‚¯è¶³")
        
        return resampled
    
    def calculate_macd_gradient(self, df, fast=12, slow=26, signal=9):
        """MACDå‹¾é…è¨ˆç®—"""
        if len(df) < slow + 10:  # ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆ
            return pd.Series([0] * len(df), index=df.index)
        
        # EMAè¨ˆç®—
        ema_fast = df['close'].ewm(span=fast, adjust=False).mean()
        ema_slow = df['close'].ewm(span=slow, adjust=False).mean()
        
        # MACDãƒ©ã‚¤ãƒ³
        macd_line = ema_fast - ema_slow
        
        # å‹¾é…è¨ˆç®—ï¼ˆ5æœŸé–“ã®å¤‰åŒ–ç‡ï¼‰
        macd_gradient = macd_line.pct_change(periods=5) * 100
        
        # -100% ~ +100% ã®ç¯„å›²ã«ã‚¯ãƒªãƒƒãƒ—
        macd_gradient = macd_gradient.clip(-100, 100).fillna(0)
        
        return macd_gradient
    
    def calculate_ma_gradient(self, df, period=20):
        """ç§»å‹•å¹³å‡å‹¾é…è¨ˆç®—"""
        if len(df) < period + 10:
            return pd.Series([0] * len(df), index=df.index)
        
        # ç§»å‹•å¹³å‡
        ma = df['close'].rolling(window=period).mean()
        
        # å‹¾é…è¨ˆç®—ï¼ˆ5æœŸé–“ã®å¤‰åŒ–ç‡ï¼‰
        ma_gradient = ma.pct_change(periods=5) * 100
        
        # -100% ~ +100% ã®ç¯„å›²ã«ã‚¯ãƒªãƒƒãƒ—
        ma_gradient = ma_gradient.clip(-100, 100).fillna(0)
        
        return ma_gradient
    
    def calculate_atr_gradient(self, df, period=14):
        """ATRå‹¾é…è¨ˆç®—"""
        if len(df) < period + 10:
            return pd.Series([0] * len(df), index=df.index)
        
        # True Rangeè¨ˆç®—
        df_copy = df.copy()
        df_copy['prev_close'] = df_copy['close'].shift(1)
        df_copy['tr1'] = df_copy['high'] - df_copy['low']
        df_copy['tr2'] = abs(df_copy['high'] - df_copy['prev_close'])
        df_copy['tr3'] = abs(df_copy['low'] - df_copy['prev_close'])
        
        df_copy['true_range'] = df_copy[['tr1', 'tr2', 'tr3']].max(axis=1)
        
        # ATRè¨ˆç®—
        atr = df_copy['true_range'].rolling(window=period).mean()
        
        # å‹¾é…è¨ˆç®—ï¼ˆ5æœŸé–“ã®å¤‰åŒ–ç‡ï¼‰
        atr_gradient = atr.pct_change(periods=5) * 100
        
        # -100% ~ +100% ã®ç¯„å›²ã«ã‚¯ãƒªãƒƒãƒ—
        atr_gradient = atr_gradient.clip(-100, 100).fillna(0)
        
        return atr_gradient
    
    def calculate_price_gradient(self, df):
        """ä¾¡æ ¼å‹¾é…è¨ˆç®—ï¼ˆçµ‚å€¤ã®å¤‰åŒ–ç‡ï¼‰"""
        price_gradient = df['close'].pct_change(periods=5) * 100
        price_gradient = price_gradient.clip(-100, 100).fillna(0)
        return price_gradient
    
    def calculate_all_gradients(self, timeframe_data):
        """å…¨æ™‚é–“è»¸ã®å‹¾é…ã‚’è¨ˆç®—"""
        gradients = {}
        
        for tf_name, df in timeframe_data.items():
            if df.empty:
                gradients[tf_name] = {
                    'macd_gradient': pd.Series([0], index=[datetime.now()]),
                    'ma_gradient': pd.Series([0], index=[datetime.now()]),
                    'atr_gradient': pd.Series([0], index=[datetime.now()]),
                    'price_gradient': pd.Series([0], index=[datetime.now()])
                }
                continue
            
            logger.info(f"   ğŸ“ˆ {tf_name} ã®å‹¾é…è¨ˆç®—ä¸­...")
            
            gradients[tf_name] = {
                'macd_gradient': self.calculate_macd_gradient(df),
                'ma_gradient': self.calculate_ma_gradient(df),
                'atr_gradient': self.calculate_atr_gradient(df),
                'price_gradient': self.calculate_price_gradient(df)
            }
        
        return gradients
    
    def get_gradient_at_time(self, gradients, target_time):
        """æŒ‡å®šæ™‚åˆ»ã®å‹¾é…ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å–å¾—"""
        pattern = []
        
        timeframe_order = ['1min', '5min', '15min', '1hour']
        
        for tf in timeframe_order:
            if tf not in gradients:
                pattern.append(0.0)
                continue
            
            tf_gradients = gradients[tf]
            
            # æŒ‡å®šæ™‚åˆ»ã«æœ€ã‚‚è¿‘ã„ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            macd_val = self._get_closest_value(tf_gradients['macd_gradient'], target_time)
            ma_val = self._get_closest_value(tf_gradients['ma_gradient'], target_time)
            atr_val = self._get_closest_value(tf_gradients['atr_gradient'], target_time)
            price_val = self._get_closest_value(tf_gradients['price_gradient'], target_time)
            
            # è¤‡åˆå‹¾é…ã‚¹ã‚³ã‚¢ï¼ˆå„æŒ‡æ¨™ã®é‡ã¿ä»˜ã‘å¹³å‡ï¼‰
            composite_gradient = (macd_val * 0.3 + ma_val * 0.3 + atr_val * 0.2 + price_val * 0.2)
            pattern.append(round(composite_gradient, 2))
        
        return pattern
    
    def _get_closest_value(self, series, target_time):
        """æŒ‡å®šæ™‚åˆ»ã«æœ€ã‚‚è¿‘ã„å€¤ã‚’å–å¾—"""
        if series.empty:
            return 0.0
        
        try:
            # target_timeãŒdatetimeã§ãªã„å ´åˆã¯å¤‰æ›
            if isinstance(target_time, str):
                target_time = pd.to_datetime(target_time)
            
            # æœ€ã‚‚è¿‘ã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¦‹ã¤ã‘ã‚‹
            idx = series.index.get_indexer([target_time], method='nearest')[0]
            if idx >= 0 and idx < len(series):
                value = series.iloc[idx]
                return float(value) if not pd.isna(value) else 0.0
            else:
                return 0.0
                
        except Exception as e:
            logger.warning(f"å€¤ã®å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
    
    def analyze_currency_pair(self, currency_pair):
        """ç‰¹å®šé€šè²¨ãƒšã‚¢ã®å‹¾é…åˆ†æ"""
        logger.info(f"ğŸ” {currency_pair} ã®å‹¾é…åˆ†æé–‹å§‹")
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        df = self.load_recent_data(currency_pair)
        if df.empty:
            return None
        
        # æ™‚é–“è»¸åˆ¥ã«ãƒªã‚µãƒ³ãƒ—ãƒ«
        logger.info(f"â° æ™‚é–“è»¸åˆ¥ãƒªã‚µãƒ³ãƒ—ãƒ«å®Ÿè¡Œ...")
        timeframe_data = self.resample_to_timeframes(df)
        
        # å‹¾é…è¨ˆç®—
        logger.info(f"ğŸ“Š å‹¾é…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨ˆç®—...")
        gradients = self.calculate_all_gradients(timeframe_data)
        
        # ã‚µãƒ³ãƒ—ãƒ«æ™‚åˆ»ã§ã®å‹¾é…ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¡¨ç¤º
        sample_times = [
            datetime.now() - timedelta(hours=1),
            datetime.now() - timedelta(hours=2),
            datetime.now() - timedelta(hours=6),
            datetime.now() - timedelta(hours=12)
        ]
        
        results = []
        for sample_time in sample_times:
            pattern = self.get_gradient_at_time(gradients, sample_time)
            results.append({
                'time': sample_time.strftime('%Y-%m-%d %H:%M'),
                'pattern': pattern
            })
            logger.info(f"   {sample_time.strftime('%H:%M')}: {pattern}")
        
        return {
            'currency_pair': currency_pair,
            'gradients': gradients,
            'sample_results': results
        }
    
    def test_gradient_calculation(self, target_currency='USDJPY'):
        """å‹¾é…è¨ˆç®—ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        logger.info("ğŸš€ FXå‹¾é…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨ˆç®—ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # åˆ©ç”¨å¯èƒ½é€šè²¨ãƒšã‚¢è¡¨ç¤º
        available_pairs = self.get_available_currency_pairs()
        logger.info(f"ğŸ“‹ åˆ©ç”¨å¯èƒ½é€šè²¨ãƒšã‚¢: {available_pairs}")
        
        if target_currency not in available_pairs:
            logger.error(f"âŒ {target_currency} ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
        
        # å‹¾é…åˆ†æå®Ÿè¡Œ
        result = self.analyze_currency_pair(target_currency)
        
        if result:
            logger.info("âœ… å‹¾é…è¨ˆç®—ãƒ†ã‚¹ãƒˆå®Œäº†")
            
            # çµæœã®ä¿å­˜
            output_file = f"gradient_test_result_{target_currency}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            # JSONå½¢å¼ã§ä¿å­˜ï¼ˆdatetimeã¨Seriesã¯é™¤å¤–ï¼‰
            save_data = {
                'currency_pair': result['currency_pair'],
                'sample_results': result['sample_results'],
                'analysis_time': datetime.now().isoformat()
            }
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(save_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ“„ çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file}")
            return True
        else:
            logger.error("âŒ å‹¾é…è¨ˆç®—ãƒ†ã‚¹ãƒˆå¤±æ•—")
            return False

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        # å‹¾é…è¨ˆç®—å™¨ã‚’åˆæœŸåŒ–
        calculator = FXGradientCalculator()
        
        # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯USDJPYï¼‰
        success = calculator.test_gradient_calculation('USDJPY')
        
        if success:
            print("\n" + "="*60)
            print("ğŸ‰ å‹¾é…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆæˆåŠŸï¼")
            print("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
            print("1. fx_analysis_step1.py ã«å‹¾é…è¨ˆç®—æ©Ÿèƒ½ã‚’çµ±åˆ")
            print("2. ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆCSVã«å‹¾é…ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ")
            print("3. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã«çµ„ã¿è¾¼ã¿")
            print("="*60)
        else:
            print("\nâŒ ãƒ†ã‚¹ãƒˆå¤±æ•—ã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
    except Exception as e:
        logger.error(f"ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()