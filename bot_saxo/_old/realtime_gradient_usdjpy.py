#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
fx_realtime_gradient_usdjpy.py - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ USDJPYå‹¾é…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—
å®Ÿè¡Œæ™‚ç‚¹ã§ã®ãƒ‰ãƒ«å††ã®å‹¾é…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å³åº§ã«è¨ˆç®—ãƒ»è¡¨ç¤º
"""

import requests
import pandas as pd
import numpy as np
import os
import zipfile
import io
from datetime import datetime, timedelta
import logging
from config import TEST_TOKEN_24H, BASE_URL

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class RealtimeGradientUSDJPY:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ USDJPYå‹¾é…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.base_url = BASE_URL
        self.token = TEST_TOKEN_24H
        self.headers = {
            'Authorization': f'Bearer {self.token}',
            'Content-Type': 'application/json'
        }
        self.currency_pair = 'USDJPY'
        self.uic = None
        self.historical_data = None
        
        # åˆæœŸåŒ–
        self._initialize()
    
    def _initialize(self):
        """ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        logger.info("ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ USDJPYå‹¾é…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å–å¾—ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–")
        
        # USDJPYã®UICå–å¾—
        self._get_usdjpy_uic()
        
        # éå»ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        self._load_historical_data()
    
    def _get_usdjpy_uic(self):
        """USDJPYã®UICå–å¾—"""
        try:
            params = {
                'Keywords': 'USDJPY',
                'AssetTypes': 'FxSpot',
                'limit': 1
            }
            response = requests.get(f"{self.base_url}/ref/v1/instruments", headers=self.headers, params=params)
            
            if response.status_code == 200:
                instruments = response.json()
                if instruments.get('Data'):
                    self.uic = instruments['Data'][0]['Identifier']
                    logger.info(f"âœ… USDJPY UICå–å¾—æˆåŠŸ: {self.uic}")
                else:
                    raise Exception("USDJPYãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            else:
                raise Exception(f"UICå–å¾—å¤±æ•—: {response.status_code}")
                
        except Exception as e:
            logger.error(f"UICå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            raise
    
    def _load_historical_data(self):
        """éå»ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆéå»3æ—¥åˆ†ã®1åˆ†è¶³ï¼‰"""
        logger.info("ğŸ“Š éå»ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
        
        try:
            # inputãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰æœ€æ–°ã®USDJPYãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            input_dir = "input"
            today = datetime.now()
            
            # éå»1ãƒ¶æœˆåˆ†ã®ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
            for days_back in range(32):
                target_date = today - timedelta(days=days_back)
                year_month = target_date.strftime('%Y%m')
                zip_path = os.path.join(input_dir, f"USDJPY_{year_month}.zip")
                
                if os.path.exists(zip_path):
                    logger.info(f"   ğŸ“ {os.path.basename(zip_path)} ã‚’ä½¿ç”¨")
                    self.historical_data = self._extract_recent_data(zip_path, days_back=3)
                    break
            
            if self.historical_data is None or self.historical_data.empty:
                logger.warning("âš ï¸  éå»ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™")
                self._create_dummy_data()
            else:
                logger.info(f"âœ… éå»ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(self.historical_data)}è¡Œ")
                
        except Exception as e:
            logger.error(f"éå»ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            self._create_dummy_data()
    
    def _extract_recent_data(self, zip_path, days_back=3):
        """ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æœ€è¿‘ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        try:
            all_data = []
            cutoff_time = datetime.now() - timedelta(days=days_back)
            
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                csv_files = [f for f in zip_ref.namelist() if f.endswith('.csv')]
                
                for csv_file in csv_files:
                    with zip_ref.open(csv_file) as file:
                        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦è¡Œ
                        for encoding in ['utf-8', 'shift_jis', 'cp932']:
                            try:
                                content = file.read().decode(encoding)
                                df = pd.read_csv(io.StringIO(content))
                                
                                # ã‚«ãƒ©ãƒ åæ­£è¦åŒ–
                                column_mapping = {
                                    "æ—¥æ™‚": "timestamp",
                                    "å§‹å€¤(BID)": "open_bid",
                                    "é«˜å€¤(BID)": "high_bid", 
                                    "å®‰å€¤(BID)": "low_bid",
                                    "çµ‚å€¤(BID)": "close_bid",
                                    "å§‹å€¤(ASK)": "open_ask",
                                    "é«˜å€¤(ASK)": "high_ask",
                                    "å®‰å€¤(ASK)": "low_ask", 
                                    "çµ‚å€¤(ASK)": "close_ask"
                                }
                                df = df.rename(columns=column_mapping)
                                
                                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å¤‰æ›
                                df['timestamp'] = pd.to_datetime(df['timestamp'])
                                
                                # æœ€è¿‘ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
                                recent_df = df[df['timestamp'] >= cutoff_time]
                                
                                if not recent_df.empty:
                                    # ä¸­é–“ä¾¡æ ¼ã‚’è¨ˆç®—
                                    recent_df['close'] = (recent_df['close_bid'] + recent_df['close_ask']) / 2
                                    recent_df['high'] = (recent_df['high_bid'] + recent_df['high_ask']) / 2
                                    recent_df['low'] = (recent_df['low_bid'] + recent_df['low_ask']) / 2
                                    recent_df['open'] = (recent_df['open_bid'] + recent_df['open_ask']) / 2
                                    
                                    all_data.append(recent_df[['timestamp', 'open', 'high', 'low', 'close']])
                                break
                            except UnicodeDecodeError:
                                continue
            
            if all_data:
                combined_df = pd.concat(all_data, ignore_index=True)
                combined_df = combined_df.sort_values('timestamp').drop_duplicates().reset_index(drop=True)
                return combined_df
            else:
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()
    
    def _create_dummy_data(self):
        """ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
        logger.info("ğŸ”§ ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆä¸­...")
        
        # éå»3æ—¥åˆ†ã®1åˆ†è¶³ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
        end_time = datetime.now()
        start_time = end_time - timedelta(days=3)
        
        timestamps = pd.date_range(start=start_time, end=end_time, freq='1T')
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ã§USDJPYã£ã½ã„ä¾¡æ ¼ã‚’ç”Ÿæˆ
        np.random.seed(42)  # å†ç¾å¯èƒ½æ€§ã®ãŸã‚
        base_price = 143.50
        price_changes = np.random.normal(0, 0.01, len(timestamps))
        prices = base_price + np.cumsum(price_changes)
        
        self.historical_data = pd.DataFrame({
            'timestamp': timestamps,
            'open': prices,
            'high': prices + np.random.uniform(0, 0.02, len(timestamps)),
            'low': prices - np.random.uniform(0, 0.02, len(timestamps)),
            'close': prices
        })
        
        logger.info(f"âœ… ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆå®Œäº†: {len(self.historical_data)}è¡Œ")
    
    def get_current_price(self):
        """ç¾åœ¨ã®USDJPYä¾¡æ ¼ã‚’å–å¾—"""
        try:
            params = {
                'Uic': str(self.uic),
                'AssetType': 'FxSpot',
                'FieldGroups': 'Quote'
            }
            response = requests.get(f"{self.base_url}/trade/v1/infoprices", headers=self.headers, params=params)
            
            if response.status_code == 200:
                prices = response.json()
                
                if prices.get('Data'):
                    quote = prices['Data'][0].get('Quote', {})
                elif 'Quote' in prices:
                    quote = prices['Quote']
                else:
                    return None
                
                bid = quote.get('Bid', 0)
                ask = quote.get('Ask', 0)
                current_price = (bid + ask) / 2
                
                logger.info(f"ğŸ’¹ ç¾åœ¨ä¾¡æ ¼: BID={bid}, ASK={ask}, ä¸­é–“ä¾¡æ ¼={current_price:.3f}")
                return current_price
            else:
                logger.error(f"ä¾¡æ ¼å–å¾—å¤±æ•—: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"ä¾¡æ ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def add_current_price_to_history(self, current_price):
        """ç¾åœ¨ä¾¡æ ¼ã‚’å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ """
        if current_price is None:
            return
        
        try:
            # ç¾åœ¨æ™‚åˆ»ã®1åˆ†è¶³ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            current_time = datetime.now().replace(second=0, microsecond=0)
            
            new_row = {
                'timestamp': current_time,
                'open': current_price,
                'high': current_price,
                'low': current_price,
                'close': current_price
            }
            
            # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
            self.historical_data = pd.concat([
                self.historical_data,
                pd.DataFrame([new_row])
            ], ignore_index=True)
            
            # é‡è¤‡é™¤å»ã¨ã‚½ãƒ¼ãƒˆ
            self.historical_data = self.historical_data.drop_duplicates(subset=['timestamp']).sort_values('timestamp').reset_index(drop=True)
            
            logger.info(f"ğŸ“Š å±¥æ­´ãƒ‡ãƒ¼ã‚¿æ›´æ–°: {current_time} = {current_price:.3f}")
            
        except Exception as e:
            logger.error(f"å±¥æ­´ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
    
    def resample_to_timeframes(self):
        """å„æ™‚é–“è»¸ã«ãƒªã‚µãƒ³ãƒ—ãƒ«"""
        try:
            df = self.historical_data.set_index('timestamp')
            
            timeframes = {
                '1min': df.resample('1T').agg({
                    'open': 'first',
                    'high': 'max',
                    'low': 'min',
                    'close': 'last'
                }).dropna(),
                
                '5min': df.resample('5T').agg({
                    'open': 'first',
                    'high': 'max',
                    'low': 'min',
                    'close': 'last'
                }).dropna(),
                
                '15min': df.resample('15T').agg({
                    'open': 'first',
                    'high': 'max',
                    'low': 'min',
                    'close': 'last'
                }).dropna(),
                
                '1hour': df.resample('1H').agg({
                    'open': 'first',
                    'high': 'max',
                    'low': 'min',
                    'close': 'last'
                }).dropna()
            }
            
            return timeframes
            
        except Exception as e:
            logger.error(f"ãƒªã‚µãƒ³ãƒ—ãƒ«ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def calculate_macd_gradient(self, df, fast=12, slow=26):
        """MACDå‹¾é…è¨ˆç®—"""
        try:
            if len(df) < slow + 5:
                return 0.0
            
            # EMAè¨ˆç®—
            ema_fast = df['close'].ewm(span=fast, adjust=False).mean()
            ema_slow = df['close'].ewm(span=slow, adjust=False).mean()
            
            # MACDãƒ©ã‚¤ãƒ³
            macd_line = ema_fast - ema_slow
            
            # æœ€æ–°ã®å‹¾é…ï¼ˆ5æœŸé–“ã®å¤‰åŒ–ç‡ï¼‰
            if len(macd_line) >= 5:
                current_macd = macd_line.iloc[-1]
                past_macd = macd_line.iloc[-5]
                
                if past_macd != 0:
                    gradient = ((current_macd - past_macd) / abs(past_macd)) * 100
                    return max(-100, min(100, gradient))
            
            return 0.0
            
        except Exception as e:
            logger.error(f"MACDå‹¾é…è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
    
    def calculate_ma_gradient(self, df, period=20):
        """ç§»å‹•å¹³å‡å‹¾é…è¨ˆç®—"""
        try:
            if len(df) < period + 5:
                return 0.0
            
            # ç§»å‹•å¹³å‡
            ma = df['close'].rolling(window=period).mean()
            
            # æœ€æ–°ã®å‹¾é…ï¼ˆ5æœŸé–“ã®å¤‰åŒ–ç‡ï¼‰
            if len(ma) >= 5:
                current_ma = ma.iloc[-1]
                past_ma = ma.iloc[-5]
                
                if past_ma != 0:
                    gradient = ((current_ma - past_ma) / past_ma) * 100
                    return max(-100, min(100, gradient))
            
            return 0.0
            
        except Exception as e:
            logger.error(f"MAå‹¾é…è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
    
    def calculate_atr_gradient(self, df, period=14):
        """ATRå‹¾é…è¨ˆç®—"""
        try:
            if len(df) < period + 5:
                return 0.0
            
            # True Rangeè¨ˆç®—
            df_copy = df.copy()
            df_copy['prev_close'] = df_copy['close'].shift(1)
            df_copy['tr1'] = df_copy['high'] - df_copy['low']
            df_copy['tr2'] = abs(df_copy['high'] - df_copy['prev_close'])
            df_copy['tr3'] = abs(df_copy['low'] - df_copy['prev_close'])
            
            df_copy['true_range'] = df_copy[['tr1', 'tr2', 'tr3']].max(axis=1)
            
            # ATRè¨ˆç®—
            atr = df_copy['true_range'].rolling(window=period).mean()
            
            # æœ€æ–°ã®å‹¾é…ï¼ˆ5æœŸé–“ã®å¤‰åŒ–ç‡ï¼‰
            if len(atr) >= 5:
                current_atr = atr.iloc[-1]
                past_atr = atr.iloc[-5]
                
                if past_atr != 0:
                    gradient = ((current_atr - past_atr) / past_atr) * 100
                    return max(-100, min(100, gradient))
            
            return 0.0
            
        except Exception as e:
            logger.error(f"ATRå‹¾é…è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
    
    def calculate_price_gradient(self, df):
        """ä¾¡æ ¼å‹¾é…è¨ˆç®—"""
        try:
            if len(df) < 5:
                return 0.0
            
            # ä¾¡æ ¼ã®å¤‰åŒ–ç‡
            current_price = df['close'].iloc[-1]
            past_price = df['close'].iloc[-5]
            
            if past_price != 0:
                gradient = ((current_price - past_price) / past_price) * 100
                return max(-100, min(100, gradient))
            
            return 0.0
            
        except Exception as e:
            logger.error(f"ä¾¡æ ¼å‹¾é…è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.0
    
    def calculate_realtime_gradients(self):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‹¾é…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨ˆç®—"""
        logger.info("ğŸ“ˆ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‹¾é…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨ˆç®—é–‹å§‹")
        
        # ç¾åœ¨ä¾¡æ ¼å–å¾—
        current_price = self.get_current_price()
        
        # å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã«ç¾åœ¨ä¾¡æ ¼ã‚’è¿½åŠ 
        self.add_current_price_to_history(current_price)
        
        # æ™‚é–“è»¸åˆ¥ãƒªã‚µãƒ³ãƒ—ãƒ«
        timeframes = self.resample_to_timeframes()
        
        if not timeframes:
            logger.error("âŒ æ™‚é–“è»¸ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå¤±æ•—")
            return None
        
        # å„æ™‚é–“è»¸ã®å‹¾é…è¨ˆç®—
        gradients = {}
        
        for tf_name, df in timeframes.items():
            if df.empty:
                gradients[tf_name] = 0.0
                continue
            
            # å„æŒ‡æ¨™ã®å‹¾é…ã‚’è¨ˆç®—
            macd_grad = self.calculate_macd_gradient(df)
            ma_grad = self.calculate_ma_gradient(df)
            atr_grad = self.calculate_atr_gradient(df)
            price_grad = self.calculate_price_gradient(df)
            
            # è¤‡åˆå‹¾é…ï¼ˆå„æŒ‡æ¨™ã®é‡ã¿ä»˜ã‘å¹³å‡ï¼‰
            composite_gradient = (macd_grad * 0.3 + ma_grad * 0.3 + atr_grad * 0.2 + price_grad * 0.2)
            gradients[tf_name] = round(composite_gradient, 2)
            
            logger.info(f"   {tf_name}: MACD={macd_grad:.2f}, MA={ma_grad:.2f}, ATR={atr_grad:.2f}, Price={price_grad:.2f} â†’ è¤‡åˆ={composite_gradient:.2f}")
        
        # 4æ™‚é–“è»¸ãƒ‘ã‚¿ãƒ¼ãƒ³
        pattern = [
            gradients.get('1min', 0.0),
            gradients.get('5min', 0.0),
            gradients.get('15min', 0.0),
            gradients.get('1hour', 0.0)
        ]
        
        return {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'current_price': current_price,
            'gradient_pattern': pattern,
            'detailed_gradients': gradients
        }
    
    def display_results(self, result):
        """çµæœã‚’è¦‹ã‚„ã™ãè¡¨ç¤º"""
        if not result:
            print("âŒ å‹¾é…è¨ˆç®—çµæœãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        print("=" * 70)
        print("ğŸ”¥ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ USDJPYå‹¾é…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
        print("=" * 70)
        print(f"â° å–å¾—æ™‚åˆ»: {result['timestamp']}")
        print(f"ğŸ’¹ ç¾åœ¨ä¾¡æ ¼: {result['current_price']:.3f}")
        print()
        print("ğŸ“Š å‹¾é…ãƒ‘ã‚¿ãƒ¼ãƒ³ [1åˆ†è¶³, 5åˆ†è¶³, 15åˆ†è¶³, 1æ™‚é–“è¶³]:")
        print(f"   {result['gradient_pattern']}")
        print()
        print("ğŸ“ˆ è©³ç´°å‹¾é…:")
        for tf, grad in result['detailed_gradients'].items():
            trend = "ğŸ”´" if grad < -10 else "ğŸŸ¡" if grad < 10 else "ğŸŸ¢"
            print(f"   {tf:>6}: {grad:>8.2f}% {trend}")
        print()
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®š
        avg_gradient = sum(result['gradient_pattern']) / 4
        if avg_gradient > 15:
            trend_status = "ğŸš€ å¼·ã„ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰"
        elif avg_gradient > 5:
            trend_status = "ğŸ“ˆ ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰"
        elif avg_gradient > -5:
            trend_status = "â¡ï¸  ãƒ¬ãƒ³ã‚¸ç›¸å ´"
        elif avg_gradient > -15:
            trend_status = "ğŸ“‰ ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰"
        else:
            trend_status = "ğŸ’¥ å¼·ã„ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰"
        
        print(f"ğŸ¯ ç·åˆåˆ¤å®š: {trend_status} (å¹³å‡å‹¾é…: {avg_gradient:.2f}%)")
        print("=" * 70)

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    try:
        # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        gradient_system = RealtimeGradientUSDJPY()
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‹¾é…è¨ˆç®—
        result = gradient_system.calculate_realtime_gradients()
        
        # çµæœè¡¨ç¤º
        gradient_system.display_results(result)
        
    except Exception as e:
        logger.error(f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()