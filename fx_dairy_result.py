#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import pandas as pd
import numpy as np
import requests
from datetime import datetime, timedelta
import json
import sys
import glob
import matplotlib.pyplot as plt
import logging
from pathlib import Path
import zipfile
import io
import re
import argparse

# åŸºæœ¬è¨­å®š
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
HISTORICAL_DATA_DIR = os.path.join(BASE_DIR, "input")

# ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚¿ã‚¤ãƒ—ã®è¨­å®š
ENTRYPOINT_CONFIGS = {
    'yokubari': {
        'name': 'ã‚ˆãã°ã‚Šã‚¨ãƒ³ãƒˆãƒªãƒ¼',
        'input_dir': os.path.join(BASE_DIR, "entrypoint_fx_ã‚ˆãã°ã‚Š"),
        'output_dir': os.path.join(BASE_DIR, "entrypoint_fx_ã‚ˆãã°ã‚Š_result"),
        'file_pattern': "ã‚ˆãã°ã‚Šã‚¨ãƒ³ãƒˆãƒªãƒ¼_*.csv",
        'log_prefix': "yokubari",
        'output_prefix': "fx_results_yokubari"
    },
    'standard': {
        'name': 'æ¨™æº–ã‚¨ãƒ³ãƒˆãƒªãƒ¼',
        'input_dir': os.path.join(BASE_DIR, "entrypoint_fx"),
        'output_dir': os.path.join(BASE_DIR, "entrypoint_fx_result"),
        'file_pattern': "entrypoints_*.csv",
        'log_prefix': "standard",
        'output_prefix': "fx_results_standard"
    }
}

# ã‚«ãƒ©ãƒ åã®æ­£è¦åŒ–ãƒãƒƒãƒ”ãƒ³ã‚°
COLUMN_MAPPING = {
    "ÃºÅ½Å¾": "timestamp",
    "æ—¥æ™‚": "timestamp",
    "Å½n'l(BID)": "open_bid",
    "å§‹å€¤(BID)": "open_bid",
    "â€š'l(BID)": "high_bid",
    "é«˜å€¤(BID)": "high_bid",
    "Ë†Ã€'l(BID)": "low_bid",
    "å®‰å€¤(BID)": "low_bid",
    "I'l(BID)": "close_bid",
    "çµ‚å€¤(BID)": "close_bid",
    "Å½n'l(ASK)": "open_ask",
    "å§‹å€¤(ASK)": "open_ask",
    "â€š'l(ASK)": "high_ask",
    "é«˜å€¤(ASK)": "high_ask",
    "Ë†Ã€'l(ASK)": "low_ask",
    "å®‰å€¤(ASK)": "low_ask",
    "I'l(ASK)": "close_ask",
    "çµ‚å€¤(ASK)": "close_ask"
}

class FXResultAnalyzer:
    def __init__(self, entry_type='yokubari'):
        """FXçµæœåˆ†æãƒ„ãƒ¼ãƒ«ã®åˆæœŸåŒ–
        
        Parameters:
        -----------
        entry_type : str
            'yokubari' ã¾ãŸã¯ 'standard'
        """
        if entry_type not in ENTRYPOINT_CONFIGS:
            raise ValueError(f"ä¸æ­£ãªentry_type: {entry_type}. 'yokubari' ã¾ãŸã¯ 'standard' ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
        
        self.entry_type = entry_type
        self.config = ENTRYPOINT_CONFIGS[entry_type]
        self.currency_settings = self.load_currency_settings()
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        Path(self.config['output_dir']).mkdir(exist_ok=True)
        
        # ãƒ­ã‚°è¨­å®š
        log_dir = os.path.join(self.config['output_dir'], "log")
        Path(log_dir).mkdir(exist_ok=True)
        
        # ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(os.path.join(log_dir, f"fx_result_{self.config['log_prefix']}_log.txt"), encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        self.logger.info(f"ğŸš€ FXçµæœåˆ†æãƒ„ãƒ¼ãƒ«åˆæœŸåŒ–: {self.config['name']}")
        self.logger.info(f"ğŸ“ å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.config['input_dir']}")
        self.logger.info(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.config['output_dir']}")
        
    def load_currency_settings(self):
        """é€šè²¨è¨­å®šã®èª­ã¿è¾¼ã¿"""
        default_settings = {
            "USD_JPY": {"pip_value": 0.01, "lot_size": 10000},
            "EUR_JPY": {"pip_value": 0.01, "lot_size": 10000},
            "GBP_JPY": {"pip_value": 0.01, "lot_size": 10000},
            "EUR_USD": {"pip_value": 0.0001, "lot_size": 10000},
            "GBP_USD": {"pip_value": 0.0001, "lot_size": 10000},
            "AUD_JPY": {"pip_value": 0.01, "lot_size": 10000},
            "NZD_JPY": {"pip_value": 0.01, "lot_size": 10000},
            "CAD_JPY": {"pip_value": 0.01, "lot_size": 10000},
            "CHF_JPY": {"pip_value": 0.01, "lot_size": 10000}
        }
        return default_settings
    
    def extract_date_from_filename(self, file_path):
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡º"""
        filename = os.path.basename(file_path)
        
        if self.entry_type == 'yokubari':
            # ã‚ˆãã°ã‚Šã‚¨ãƒ³ãƒˆãƒªãƒ¼_20250502.csv
            match = re.search(r'ã‚ˆãã°ã‚Šã‚¨ãƒ³ãƒˆãƒªãƒ¼_(\d{8})\.csv', filename)
        else:  # standard
            # entrypoints_20250502.csv
            match = re.search(r'entrypoints_(\d{8})\.csv', filename)
        
        if match:
            return match.group(1)
        return None
    
    def get_unprocessed_files(self):
        """æœªå‡¦ç†ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ï¼ˆå½“æ—¥åˆ†é™¤å¤–ï¼‰"""
        # inputå´ã®ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        input_files = glob.glob(os.path.join(self.config['input_dir'], self.config['file_pattern']))
        
        if not input_files:
            self.logger.warning(f"ğŸ“ {self.config['name']}ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.config['input_dir']}")
            return []
        
        self.logger.info(f"ğŸ“ {self.config['name']}ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {len(input_files)}ä»¶")
        
        # å½“æ—¥ã®æ—¥ä»˜ã‚’å–å¾—
        today = datetime.now().strftime('%Y%m%d')
        self.logger.info(f"ğŸ“… å½“æ—¥æ—¥ä»˜: {today} (å½“æ—¥åˆ†ã¯é™¤å¤–ã•ã‚Œã¾ã™)")
        
        # æœªå‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ
        unprocessed_files = []
        excluded_today = 0
        
        for input_file in sorted(input_files):
            file_date = self.extract_date_from_filename(input_file)
            if not file_date:
                self.logger.warning(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ: {os.path.basename(input_file)}")
                continue
            
            # å½“æ—¥åˆ†ã¯é™¤å¤–
            if file_date == today:
                self.logger.info(f"â­ï¸  å½“æ—¥åˆ†ã®ãŸã‚é™¤å¤–: {os.path.basename(input_file)} (æ—¥ä»˜: {file_date})")
                excluded_today += 1
                continue
            
            # å¯¾å¿œã™ã‚‹outputå´ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
            output_file = os.path.join(
                self.config['output_dir'], 
                f"{self.config['output_prefix']}_{file_date}.csv"
            )
            
            if not os.path.exists(output_file):
                unprocessed_files.append((input_file, file_date))
                self.logger.info(f"âœ… æœªå‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {os.path.basename(input_file)} (æ—¥ä»˜: {file_date})")
            else:
                self.logger.info(f"â­ï¸  æ—¢ã«å‡¦ç†æ¸ˆã¿: {os.path.basename(input_file)} â†’ {os.path.basename(output_file)}")
        
        # çµæœã‚µãƒãƒªãƒ¼
        if excluded_today > 0:
            self.logger.info(f"ğŸ“… å½“æ—¥åˆ†é™¤å¤–: {excluded_today}ä»¶")
        
        if not unprocessed_files:
            self.logger.info("ğŸ‰ ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå‡¦ç†æ¸ˆã¿ã§ã™ï¼ˆå½“æ—¥åˆ†é™¤ãï¼‰")
        else:
            self.logger.info(f"ğŸ“Š æœªå‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«ç·æ•°: {len(unprocessed_files)}ä»¶")
        
        return unprocessed_files
    
    def normalize_date(self, date_str):
        """æ—¥ä»˜æ–‡å­—åˆ—ã‚’YYYYMMDDå½¢å¼ã«æ¨™æº–åŒ–"""
        if not date_str:
            return None
            
        # YYYY/MM/DD -> YYYYMMDD
        if '/' in date_str:
            parts = date_str.split('/')
            if len(parts) == 3:
                return f"{parts[0]}{int(parts[1]):02d}{int(parts[2]):02d}"
        
        # ã™ã§ã«YYYYMMDDå½¢å¼ã®å ´åˆ
        if len(date_str) == 8 and date_str.isdigit():
            return date_str
        
        # ãã®ä»–ã®å½¢å¼ï¼ˆä¾‹ï¼šYYYY-MM-DDï¼‰
        if '-' in date_str:
            parts = date_str.split('-')
            if len(parts) == 3:
                return f"{parts[0]}{int(parts[1]):02d}{int(parts[2]):02d}"
                
        self.logger.warning(f"æœªå¯¾å¿œã®æ—¥ä»˜å½¢å¼: {date_str}")
        return date_str
    
    def convert_currency_name(self, name):
        """é€šè²¨ãƒšã‚¢åã‚’æ¨™æº–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›"""
        conversion = {
            "ç±³ãƒ‰ãƒ«/å††": "USD_JPY",
            "ãƒ¦ãƒ¼ãƒ­/å††": "EUR_JPY",
            "è‹±ãƒãƒ³ãƒ‰/å††": "GBP_JPY",
            "è±ªãƒ‰ãƒ«/å††": "AUD_JPY",
            "NZãƒ‰ãƒ«/å††": "NZD_JPY",
            "ãƒ¦ãƒ¼ãƒ­/ç±³ãƒ‰ãƒ«": "EUR_USD",
            "è‹±ãƒãƒ³ãƒ‰/ç±³ãƒ‰ãƒ«": "GBP_USD",
            "åŠ ãƒ‰ãƒ«/å††": "CAD_JPY",
            "ã‚¹ã‚¤ã‚¹ãƒ•ãƒ©ãƒ³/å††": "CHF_JPY",
            "USDJPY": "USD_JPY",
            "EURJPY": "EUR_JPY",
            "GBPJPY": "GBP_JPY",
            "AUDJPY": "AUD_JPY",
            "NZDJPY": "NZD_JPY",
            "EURUSD": "EUR_USD",
            "GBPUSD": "GBP_USD",
            "CADJPY": "CAD_JPY",
            "CHFJPY": "CHF_JPY"
        }
        return conversion.get(name, name)
    
    def parse_entry_data(self, entry_str):
        """ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’è§£æã—ã¦ä¾¡æ ¼ã¨æ™‚é–“ã‚’æŠ½å‡º"""
        if not entry_str or not isinstance(entry_str, str):
            return None, None
            
        # ã‚«ãƒ³ãƒã§åˆ†å‰²ã•ã‚Œã¦ã„ã‚‹å ´åˆã®å‡¦ç†
        parts = entry_str.split(',')
        if len(parts) > 1:
            price_str = parts[0].strip()
            time_str = parts[1].strip()
            
            try:
                price = float(price_str.replace(',', ''))
                return price, time_str
            except ValueError:
                pass
        
        # æ™‚é–“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
        time_patterns = [
            r'\d{1,2}:\d{2}:\d{2}',  # 14:30:00
            r'\d{1,2}:\d{2}',         # 14:30
        ]
        
        for pattern in time_patterns:
            match = re.search(pattern, entry_str)
            if match:
                time_str = match.group(0)
                price_part = entry_str.replace(time_str, '').strip()
                if price_part:
                    try:
                        price = float(price_part.replace(',', ''))
                        return price, time_str
                    except ValueError:
                        pass
                return None, time_str
        
        # æ•°å€¤ã®ã¿ã®å ´åˆ
        try:
            price = float(entry_str.replace(',', ''))
            return price, None
        except ValueError:
            return None, None
    
    def convert_to_zip_format(self, currency_pair):
        """é€šè²¨ãƒšã‚¢ã‚’ZIPãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›"""
        return currency_pair.replace("_", "")
    
    def calculate_pips(self, entry_price, exit_price, currency_pair, trade_type):
        """pipsã‚’è¨ˆç®—"""
        if currency_pair not in self.currency_settings:
            self.logger.warning(f"é€šè²¨ãƒšã‚¢{currency_pair}ã®è¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            pip_value = 0.01 if currency_pair.endswith("JPY") else 0.0001
        else:
            pip_value = self.currency_settings[currency_pair]["pip_value"]
        
        if trade_type.upper() in ["BUY", "LONG", "è²·ã„", "Long"]:
            pips = (exit_price - entry_price) / pip_value
        else:  # SELL, SHORT, å£²ã‚Š, Short
            pips = (entry_price - exit_price) / pip_value
        
        return round(pips, 1)
    
    def find_csv_in_zip(self, zip_file_path, currency_pair, date_str):
        """ZIPãƒ•ã‚¡ã‚¤ãƒ«å†…ã®æŒ‡å®šæ—¥ä»˜ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
        normalized_date = self.normalize_date(date_str)
        self.logger.info(f"æ¤œç´¢å¯¾è±¡æ—¥ä»˜: {normalized_date}, ZIPãƒ•ã‚¡ã‚¤ãƒ«: {zip_file_path}")
        
        try:
            with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
                file_list = zip_ref.namelist()
                self.logger.info(f"ZIPãƒ•ã‚¡ã‚¤ãƒ«å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(file_list)}")
                
                # 1. ç›´æ¥ãƒãƒƒãƒã™ã‚‹æ—¥ä»˜ã‚’æ¢ã™
                direct_matches = []
                for file_path in file_list:
                    clean_path = file_path.replace('\\', '/').replace('_', '').replace('-', '')
                    if normalized_date in clean_path and file_path.endswith('.csv'):
                        direct_matches.append(file_path)
                
                if direct_matches:
                    self.logger.info(f"ç›´æ¥ãƒãƒƒãƒã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {direct_matches}")
                    return direct_matches[0]
                
                # 2. ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€å†…ã®æ—¥ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
                for file_path in file_list:
                    path_parts = file_path.replace('\\', '/').split('/')
                    if len(path_parts) > 1 and path_parts[-1].endswith('.csv'):
                        if normalized_date in path_parts[-1].replace('_', '').replace('-', ''):
                            self.logger.info(f"ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {file_path}")
                            return file_path
                
                # 3. å¹´æœˆã®ã¿ã®ãƒãƒƒãƒãƒ³ã‚°
                year_month = normalized_date[:6]
                for file_path in file_list:
                    if year_month in file_path.replace('_', '').replace('-', '') and file_path.endswith('.csv'):
                        day_part = normalized_date[6:]
                        if day_part in file_path.replace('_', '').replace('-', ''):
                            self.logger.info(f"å¹´æœˆ+æ—¥ãƒãƒƒãƒã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ: {file_path}")
                            return file_path
                
                # 4. CSVãƒ•ã‚¡ã‚¤ãƒ«ã§æœ€åˆã«è¦‹ã¤ã‹ã£ãŸã‚‚ã®ã‚’ä½¿ç”¨
                csv_files = [f for f in file_list if f.endswith('.csv')]
                if csv_files:
                    self.logger.warning(f"æ—¥ä»˜ã«ä¸€è‡´ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€æœ€åˆã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨: {csv_files[0]}")
                    return csv_files[0]
                
                self.logger.error(f"ZIPãƒ•ã‚¡ã‚¤ãƒ«å†…ã«CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {zip_file_path}")
                return None
                
        except Exception as e:
            self.logger.error(f"ZIPãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def get_historical_data(self, currency_pair, date_str):
        """ç‰¹å®šã®é€šè²¨ãƒšã‚¢ã¨æ—¥ä»˜ã®ãƒ’ã‚¹ãƒˆãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        try:
            normalized_date = self.normalize_date(date_str)
            year_month = normalized_date[:6]
            zip_currency = self.convert_to_zip_format(currency_pair)
            
            patterns = [
                f"{zip_currency.upper()}_{year_month}.zip",
                f"{zip_currency.lower()}_{year_month}.zip",
                f"{zip_currency}_{year_month}.zip"
            ]
            
            all_zip_files = glob.glob(os.path.join(HISTORICAL_DATA_DIR, "*.zip"))
            
            matching_zips = []
            for pattern in patterns:
                expected_path = os.path.join(HISTORICAL_DATA_DIR, pattern)
                if os.path.exists(expected_path):
                    matching_zips.append(expected_path)
                else:
                    for zip_file in all_zip_files:
                        zip_name = os.path.basename(zip_file)
                        if zip_currency.upper() in zip_name.upper() and year_month in zip_name:
                            matching_zips.append(zip_file)
            
            if not matching_zips:
                for zip_file in all_zip_files:
                    zip_name = os.path.basename(zip_file)
                    if zip_currency.upper() in zip_name.upper():
                        matching_zips.append(zip_file)
            
            if not matching_zips:
                self.logger.error(f"é€šè²¨ãƒšã‚¢ {currency_pair} ã«ä¸€è‡´ã™ã‚‹ZIPãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None
            
            zip_file_path = max(matching_zips, key=os.path.getmtime)
            csv_file_path = self.find_csv_in_zip(zip_file_path, currency_pair, normalized_date)
            
            if not csv_file_path:
                self.logger.error(f"æŒ‡å®šæ—¥ä»˜ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {normalized_date}")
                return None
            
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
                encodings = ['utf-8', 'shift_jis', 'cp932', 'euc_jp', 'iso-8859-1']
                
                for encoding in encodings:
                    try:
                        with zip_ref.open(csv_file_path) as csv_file:
                            csv_content = csv_file.read().decode(encoding)
                            df = pd.read_csv(io.StringIO(csv_content))
                            break
                    except UnicodeDecodeError:
                        continue
                    except Exception as e:
                        self.logger.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
                        return None
                else:
                    self.logger.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç‰¹å®šã§ãã¾ã›ã‚“")
                    return None
                
                # ã‚«ãƒ©ãƒ åã‚’æ¨™æº–åŒ–
                renamed_columns = {}
                for col in df.columns:
                    if col in COLUMN_MAPPING:
                        renamed_columns[col] = COLUMN_MAPPING[col]
                    else:
                        col_str = str(col)
                        if "BID" in col_str.upper() and "å§‹å€¤" in col_str:
                            renamed_columns[col] = "open_bid"
                        elif "BID" in col_str.upper() and "é«˜å€¤" in col_str:
                            renamed_columns[col] = "high_bid"
                        elif "BID" in col_str.upper() and "å®‰å€¤" in col_str:
                            renamed_columns[col] = "low_bid"
                        elif "BID" in col_str.upper() and "çµ‚å€¤" in col_str:
                            renamed_columns[col] = "close_bid"
                        elif "ASK" in col_str.upper() and "å§‹å€¤" in col_str:
                            renamed_columns[col] = "open_ask"
                        elif "ASK" in col_str.upper() and "é«˜å€¤" in col_str:
                            renamed_columns[col] = "high_ask"
                        elif "ASK" in col_str.upper() and "å®‰å€¤" in col_str:
                            renamed_columns[col] = "low_ask"
                        elif "ASK" in col_str.upper() and "çµ‚å€¤" in col_str:
                            renamed_columns[col] = "close_ask"
                        elif "æ—¥æ™‚" in col_str:
                            renamed_columns[col] = "timestamp"
                
                if renamed_columns:
                    df = df.rename(columns=renamed_columns)
                
                return df
            
        except Exception as e:
            self.logger.error(f"ãƒ’ã‚¹ãƒˆãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def get_rate_at_time(self, df, time_str):
        """æŒ‡å®šæ™‚é–“ã®ãƒ¬ãƒ¼ãƒˆã‚’å–å¾—"""
        try:
            if len(time_str.split(':')) == 2:
                time_str += ":00"
                
            target_time = pd.to_datetime(time_str)
            
            if 'timestamp' in df.columns:
                if df['timestamp'].dtype == object:
                    sample_timestamp = df['timestamp'].iloc[0] if not df.empty else None
                    
                    if isinstance(sample_timestamp, str) and '/' in sample_timestamp:
                        df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y/%m/%d %H:%M:%S', errors='coerce')
                    else:
                        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
            
                if 'timestamp' in df.columns and not df.empty:
                    df['time_only'] = df['timestamp'].dt.time
                    target_time_only = target_time.time()
                    
                    exact_match = df[df['time_only'] == target_time_only]
                    
                    if not exact_match.empty:
                        row = exact_match.iloc[0]
                        return {
                            "bid": row.get('close_bid'),
                            "ask": row.get('close_ask'),
                            "timestamp": row.get('timestamp')
                        }
                    
                    df['time_diff'] = df['time_only'].apply(lambda t: 
                        abs((t.hour * 3600 + t.minute * 60 + t.second) - 
                            (target_time_only.hour * 3600 + target_time_only.minute * 60 + target_time_only.second)))
                    
                    closest_idx = df['time_diff'].idxmin()
                    closest_row = df.loc[closest_idx]
                    
                    return {
                        "bid": closest_row.get('close_bid'),
                        "ask": closest_row.get('close_ask'),
                        "timestamp": closest_row.get('timestamp')
                    }
                else:
                    target_idx = (target_time.hour * 60) + target_time.minute
                    
                    if 0 <= target_idx < len(df):
                        row = df.iloc[target_idx]
                        return {
                            "bid": row.get('close_bid'),
                            "ask": row.get('close_ask'),
                            "timestamp": target_time
                        }
            
            return None
            
        except Exception as e:
            self.logger.error(f"ãƒ¬ãƒ¼ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def standardize_columns(self, df):
        """ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸã‚«ãƒ©ãƒ åã®æ¨™æº–åŒ–"""
        column_mappings = {}
        
        for col in df.columns:
            col_str = str(col)
            
            if any(keyword in col_str for keyword in ['Ğšâ€°Ğ­Ñ“yÑ“A', 'currency', 'pair', 'é€šè²¨']):
                column_mappings[col] = 'é€šè²¨ãƒšã‚¢'
            elif any(keyword in col_str for keyword in ['Entry', 'entry', 'ã‚¨ãƒ³ãƒˆãƒªãƒ¼']):
                column_mappings[col] = 'Entry'
            elif any(keyword in col_str for keyword in ['Exit', 'exit', 'ã‚¨ã‚°ã‚¸ãƒƒãƒˆ']):
                column_mappings[col] = 'Exit'
            elif any(keyword in col_str for keyword in ['â€¢Ñ‹ĞŠÑŒ', 'direction', 'type', 'æ–¹å‘']):
                column_mappings[col] = 'æ–¹å‘'
            elif any(keyword in col_str for keyword in ['"ÑŠâ€¢t', 'date', 'æ—¥ä»˜']):
                column_mappings[col] = 'æ—¥ä»˜'
            elif 'score' in col_str.lower() or 'ã‚¹ã‚³ã‚¢' in col_str:
                if 'å®Ÿç”¨' in col_str or 'practical' in col_str:
                    column_mappings[col] = 'å®Ÿç”¨ã‚¹ã‚³ã‚¢'
                elif 'ç·åˆ' in col_str or 'total' in col_str:
                    column_mappings[col] = 'ç·åˆã‚¹ã‚³ã‚¢'
            elif 'å‹ç‡' in col_str or 'win' in col_str.lower():
                if 'çŸ­æœŸ' in col_str or 'short' in col_str:
                    column_mappings[col] = 'çŸ­æœŸå‹ç‡'
                elif 'ä¸­æœŸ' in col_str or 'mid' in col_str:
                    column_mappings[col] = 'ä¸­æœŸå‹ç‡'
                elif 'é•·æœŸ' in col_str or 'long' in col_str:
                    column_mappings[col] = 'é•·æœŸå‹ç‡'
        
        if column_mappings:
            df = df.rename(columns=column_mappings)
            self.logger.info(f"ã‚«ãƒ©ãƒ åã‚’ç½®æ›ã—ã¾ã—ãŸ: {column_mappings}")
        
        return df

    def process_single_file(self, file_path, file_date):
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†"""
        self.logger.info(f"ğŸ“Š å‡¦ç†é–‹å§‹: {os.path.basename(file_path)} (æ—¥ä»˜: {file_date})")
        
        # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        result_file = os.path.join(
            self.config['output_dir'], 
            f"{self.config['output_prefix']}_{file_date}.csv"
        )
        
        try:
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            encodings = ['utf-8', 'utf-8-sig', 'shift_jis', 'cp932', 'euc_jp']
            df = None
            
            for encoding in encodings:
                try:
                    df = pd.read_csv(file_path, encoding=encoding)
                    self.logger.info(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° {encoding}")
                    break
                except UnicodeDecodeError:
                    continue
                except Exception as e:
                    self.logger.error(f"CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({encoding}): {str(e)}")
            
            if df is None:
                self.logger.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ: {file_path}")
                return False
            
            # ã‚«ãƒ©ãƒ åã®æ¨™æº–åŒ–
            df = self.standardize_columns(df)
            
            # å¿…è¦ãªã‚«ãƒ©ãƒ ã®ç¢ºèª
            required_columns = ['é€šè²¨ãƒšã‚¢', 'Entry', 'æ–¹å‘']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                self.logger.error(f"å¿…è¦ãªã‚«ãƒ©ãƒ ãŒã‚ã‚Šã¾ã›ã‚“: {', '.join(missing_columns)}")
                return False
            
            # çµæœç”¨ã®ã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
            result_columns = ['Entryä¾¡æ ¼', 'Exitä¾¡æ ¼', 'å‹æ•—', 'pips']
            for col in result_columns:
                if col not in df.columns:
                    df[col] = None
            
            # å„ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’å‡¦ç†
            for idx, row in df.iterrows():
                currency_name = row['é€šè²¨ãƒšã‚¢']
                currency_pair = self.convert_currency_name(currency_name)
                entry_str = row['Entry']
                
                # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã®è§£æ
                entry_price, entry_time = self.parse_entry_data(entry_str)
                
                if not entry_time and isinstance(entry_str, str) and ':' in entry_str:
                    entry_time = entry_str
                
                if not entry_price and not entry_time:
                    self.logger.warning(f"è¡Œ {idx+1}: ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒ‡ãƒ¼ã‚¿ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {entry_str}")
                    continue
                
                # Exitæ™‚åˆ»ã®å–å¾—
                exit_time = None
                if 'Exit' in df.columns and pd.notna(row['Exit']):
                    exit_str = row['Exit']
                    _, exit_time = self.parse_entry_data(exit_str)
                    if not exit_time and isinstance(exit_str, str) and ':' in exit_str:
                        exit_time = exit_str
                
                if not exit_time:
                    self.logger.warning(f"è¡Œ {idx+1}: Exitæ™‚åˆ»ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                    continue
                
                # ãƒ’ã‚¹ãƒˆãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                historical_data = self.get_historical_data(currency_pair, file_date)
                
                if historical_data is None:
                    self.logger.error(f"è¡Œ {idx+1}: ãƒ’ã‚¹ãƒˆãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    continue
                
                # Entryä¾¡æ ¼ã®å–å¾—
                if not entry_price and entry_time:
                    rate_at_entry = self.get_rate_at_time(historical_data, entry_time)
                    if rate_at_entry:
                        trade_direction = row['æ–¹å‘']
                        if trade_direction.upper() in ["BUY", "LONG", "è²·ã„", "Long"]:
                            entry_price = rate_at_entry["ask"]
                        else:
                            entry_price = rate_at_entry["bid"]
                        self.logger.info(f"è¡Œ {idx+1}: Entryæ™‚é–“ {entry_time} ã®ãƒ¬ãƒ¼ãƒˆ: {entry_price}")
                    else:
                        self.logger.warning(f"è¡Œ {idx+1}: Entryæ™‚é–“ {entry_time} ã®ãƒ¬ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                        continue
                
                # Exitä¾¡æ ¼ã®å–å¾—ï¼ˆä¿®æ­£ç®‡æ‰€ï¼‰
                trade_direction = row['æ–¹å‘']
                rate_at_exit = self.get_rate_at_time(historical_data, exit_time)
                
                if rate_at_exit:
                    if trade_direction.upper() in ["BUY", "LONG", "è²·ã„", "Long"]:
                        exit_price = rate_at_exit["bid"]  # è²·ã„ãƒã‚¸ã‚·ãƒ§ãƒ³ã®æ±ºæ¸ˆã¯BID
                    else:  # "SELL", "SHORT", "å£²ã‚Š", "Short"
                        exit_price = rate_at_exit["ask"]  # å£²ã‚Šãƒã‚¸ã‚·ãƒ§ãƒ³ã®æ±ºæ¸ˆã¯ASK
                    
                    self.logger.info(f"è¡Œ {idx+1}: Exitæ™‚é–“ {exit_time} ã®ãƒ¬ãƒ¼ãƒˆ: {exit_price}")
                else:
                    self.logger.warning(f"è¡Œ {idx+1}: Exitæ™‚é–“ {exit_time} ã®ãƒ¬ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                    continue
                
                # pipsã®è¨ˆç®—
                pips = self.calculate_pips(entry_price, exit_price, currency_pair, trade_direction)
                
                # å‹æ•—åˆ¤å®š
                if pips > 0:
                    win_loss = "WIN"
                elif pips < 0:
                    win_loss = "LOSS"
                else:
                    win_loss = "EVEN"
                
                # çµæœã‚’æ›´æ–°
                df.at[idx, 'Entryä¾¡æ ¼'] = entry_price
                df.at[idx, 'Exitä¾¡æ ¼'] = exit_price
                df.at[idx, 'å‹æ•—'] = win_loss
                df.at[idx, 'pips'] = pips
            
            # çµæœã‚’ä¿å­˜
            df.to_csv(result_file, index=False, encoding='shift_jis')
            self.logger.info(f"çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {result_file}")
            
            # çµæœã®è¦ç´„ã‚’è¡¨ç¤º
            wins = df[df['å‹æ•—'] == 'WIN'].shape[0]
            losses = df[df['å‹æ•—'] == 'LOSS'].shape[0]
            evens = df[df['å‹æ•—'] == 'EVEN'].shape[0]
            total_pips = df['pips'].sum()
            
            self.logger.info(f"åˆ†æçµæœ:")
            self.logger.info(f"  ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚¿ã‚¤ãƒ—: {self.config['name']}")
            self.logger.info(f"  åˆ†æå¯¾è±¡æ—¥: {file_date}")
            self.logger.info(f"  ç·å–å¼•æ•°: {len(df)}")
            self.logger.info(f"  å‹ã¡: {wins}, è² ã‘: {losses}, å¼•ãåˆ†ã‘: {evens}")
            if wins + losses > 0:
                self.logger.info(f"  å‹ç‡: {wins/(wins+losses)*100:.1f}%")
            self.logger.info(f"  åˆè¨ˆpips: {total_pips:.1f}")
            
            # ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ
            self.generate_report(df, file_date)
            
            return True
            
        except Exception as e:
            self.logger.error(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            self.logger.error(traceback.format_exc())
            return False

    def process_all_unprocessed_files(self):
        """æœªå‡¦ç†ã®ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†"""
        unprocessed_files = self.get_unprocessed_files()
        
        if not unprocessed_files:
            self.logger.info("ğŸ‰ å‡¦ç†å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå‡¦ç†æ¸ˆã¿ã§ã™ã€‚")
            return True
        
        self.logger.info(f"ğŸš€ ä¸€æ‹¬å‡¦ç†é–‹å§‹: {len(unprocessed_files)}ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¾ã™")
        
        success_count = 0
        failure_count = 0
        
        for i, (file_path, file_date) in enumerate(unprocessed_files, 1):
            self.logger.info(f"ğŸ“Š é€²æ—: {i}/{len(unprocessed_files)} - {os.path.basename(file_path)}")
            
            if self.process_single_file(file_path, file_date):
                success_count += 1
                self.logger.info(f"âœ… å‡¦ç†æˆåŠŸ: {os.path.basename(file_path)}")
            else:
                failure_count += 1
                self.logger.error(f"âŒ å‡¦ç†å¤±æ•—: {os.path.basename(file_path)}")
        
        # å‡¦ç†çµæœã®é›†è¨ˆ
        self.logger.info(f"ğŸ“Š ä¸€æ‹¬å‡¦ç†å®Œäº†:")
        self.logger.info(f"  å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(unprocessed_files)}")
        self.logger.info(f"  æˆåŠŸ: {success_count}")
        self.logger.info(f"  å¤±æ•—: {failure_count}")
        
        if failure_count == 0:
            self.logger.info("ğŸ‰ ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«å‡¦ç†ã•ã‚Œã¾ã—ãŸï¼")
        else:
            self.logger.warning(f"âš ï¸  {failure_count}ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        return failure_count == 0

    def generate_report(self, df, file_date):
        """çµæœãƒ¬ãƒãƒ¼ãƒˆã¨ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ"""
        try:
            # ã‚°ãƒ©ãƒ•ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            chart_dir = os.path.join(self.config['output_dir'], "charts")
            Path(chart_dir).mkdir(exist_ok=True)
            
            # çµæœã®æ¦‚è¦ã‚°ãƒ©ãƒ•
            plt.figure(figsize=(10, 6))
            
            # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š
            import matplotlib as mpl
            plt.rcParams['font.family'] = 'sans-serif'
            
            # Windowsç’°å¢ƒ
            if os.name == 'nt':
                font_dirs = [os.path.join(os.environ['WINDIR'], 'Fonts')]
                font_files = mpl.font_manager.findSystemFonts(fontpaths=font_dirs)
                
                for font_file in font_files:
                    if any(name in font_file.lower() for name in ['msgothic', 'meiryo', 'yugothic', 'arial', 'tahoma']):
                        mpl.font_manager.fontManager.addfont(font_file)
                
                plt.rcParams['font.sans-serif'] = ['MS Gothic', 'Meiryo', 'Yu Gothic', 'Arial', 'Tahoma', 'DejaVu Sans']
            # macOSç’°å¢ƒ
            elif sys.platform == 'darwin':
                plt.rcParams['font.sans-serif'] = ['Hiragino Sans', 'Hiragino Kaku Gothic Pro', 'AppleGothic', 'Arial', 'Tahoma', 'DejaVu Sans']
            # Linuxç’°å¢ƒ
            else:
                plt.rcParams['font.sans-serif'] = ['IPAGothic', 'VL Gothic', 'Noto Sans CJK JP', 'Takao Gothic', 'Arial', 'Tahoma', 'DejaVu Sans']
            
            # å‹æ•—å††ã‚°ãƒ©ãƒ•
            plt.subplot(1, 2, 1)
            win_counts = df['å‹æ•—'].value_counts()
            if not win_counts.empty:
                labels = win_counts.index
                sizes = win_counts.values
                colors = ['green' if x == 'WIN' else 'red' if x == 'LOSS' else 'gray' for x in labels]
                plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
                plt.axis('equal')
                plt.title(f'{self.config["name"]} - Trading Results')
            else:
                plt.text(0.5, 0.5, 'No Data', horizontalalignment='center', verticalalignment='center')
            
            # é€šè²¨ãƒšã‚¢åˆ¥pipsã®ãƒãƒ¼ã‚°ãƒ©ãƒ•
            plt.subplot(1, 2, 2)
            currency_pips = df.groupby('é€šè²¨ãƒšã‚¢')['pips'].sum()
            if not currency_pips.empty:
                colors = ['green' if x >= 0 else 'red' for x in currency_pips.values]
                currency_pips.plot(kind='bar', color=colors)
                plt.title(f'{self.config["name"]} - Pips by Currency Pair')
                plt.ylabel('pips')
            else:
                plt.text(0.5, 0.5, 'No Data', horizontalalignment='center', verticalalignment='center')
                
            plt.tight_layout()
            
            # ã‚°ãƒ©ãƒ•ã®ä¿å­˜
            chart_path = os.path.join(chart_dir, f"{self.config['output_prefix']}_{file_date}.png")
            plt.savefig(chart_path)
            plt.close()
            
            self.logger.info(f"ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {chart_path}")
            
            # HTMLãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
            self.generate_html_report(df, file_date)
                
        except Exception as e:
            self.logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            self.logger.error(traceback.format_exc())

    def generate_html_report(self, df, file_date):
        """HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        try:
            html_content = f"""
            <!DOCTYPE html>
            <html lang="ja">
            <head>
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <title>FXå–å¼•çµæœ {file_date} - {self.config['name']}</title>
                <style>
                    body {{ font-family: Arial, sans-serif; margin: 20px; }}
                    h1, h2 {{ color: #2c3e50; }}
                    table {{ border-collapse: collapse; width: 100%; margin-bottom: 20px; }}
                    th, td {{ text-align: left; padding: 8px; border: 1px solid #ddd; }}
                    th {{ background-color: #f2f2f2; }}
                    tr:nth-child(even) {{ background-color: #f9f9f9; }}
                    .win {{ color: green; }}
                    .loss {{ color: red; }}
                    .even {{ color: gray; }}
                    .summary {{ background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin-bottom: 20px; }}
                    img {{ max-width: 100%; height: auto; margin: 20px 0; }}
                    .analysis-info {{ background-color: #e3f2fd; padding: 15px; border-radius: 5px; margin-bottom: 20px; }}
                    .entry-type {{ background-color: #fff3e0; padding: 10px; border-radius: 5px; margin-bottom: 15px; }}
                </style>
            </head>
            <body>
                <h1>FXå–å¼•çµæœãƒ¬ãƒãƒ¼ãƒˆ - {file_date}</h1>
                
                <div class="entry-type">
                    <h2>ğŸ“Š ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚¿ã‚¤ãƒ—: {self.config['name']}</h2>
                    <p><strong>å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€:</strong> {self.config['input_dir']}</p>
                    <p><strong>å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€:</strong> {self.config['output_dir']}</p>
                </div>
                
                <div class="analysis-info">
                    <h2>ğŸ“Š åˆ†ææƒ…å ±</h2>
                    <p><strong>åˆ†æå¯¾è±¡æ—¥:</strong> {file_date}</p>
                    <p><strong>åˆ†ææ–¹å¼:</strong> æœªå‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•æ¤œå‡ºãƒ»ä¸€æ‹¬å‡¦ç†</p>
                    <p><strong>å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯:</strong> inputå´å­˜åœ¨ âˆ§ outputå´æœªå­˜åœ¨ â†’ åˆ†æå®Ÿè¡Œ</p>
                </div>
                
                <div class="summary">
                    <h2>å–å¼•æ¦‚è¦</h2>
                    <p>ç·å–å¼•æ•°: {len(df)}</p>
            """
            
            # å‹æ•—ãƒ‡ãƒ¼ã‚¿ã‚’å®‰å…¨ã«å–å¾—
            win_count = df[df['å‹æ•—'] == 'WIN'].shape[0]
            loss_count = df[df['å‹æ•—'] == 'LOSS'].shape[0]
            even_count = df[df['å‹æ•—'] == 'EVEN'].shape[0]
            pips_sum = df['pips'].sum() if not df.empty and 'pips' in df.columns and df['pips'].notna().any() else 0.0
            
            html_content += f"""
                    <p>å‹ã¡: <span class="win">{win_count}</span></p>
                    <p>è² ã‘: <span class="loss">{loss_count}</span></p>
                    <p>å¼•ãåˆ†ã‘: <span class="even">{even_count}</span></p>
            """
            
            # å‹ç‡ã®è¨ˆç®—ï¼ˆã‚¼ãƒ­é™¤ç®—ã‚’å›é¿ï¼‰
            if win_count + loss_count > 0:
                win_rate = win_count / (win_count + loss_count) * 100
                html_content += f'    <p>å‹ç‡: {win_rate:.1f}%</p>\n'
            else:
                html_content += '    <p>å‹ç‡: 0.0%</p>\n'
                
            html_content += f'    <p>åˆè¨ˆpips: {pips_sum:.1f}</p>\n'
            html_content += """
                </div>
                
                <h2>å–å¼•è©³ç´°</h2>
                <table>
                    <tr>
                        <th>No</th>
                        <th>é€šè²¨ãƒšã‚¢</th>
                        <th>æ–¹å‘</th>
                        <th>Entry</th>
            """
            
            # Exitã‚«ãƒ©ãƒ ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
            if 'Exit' in df.columns:
                html_content += "<th>Exit</th>"
            
            html_content += """
                        <th>Entryä¾¡æ ¼</th>
                        <th>Exitä¾¡æ ¼</th>
                        <th>å‹æ•—</th>
                        <th>pips</th>
                    </tr>
            """
            
            for idx, row in df.iterrows():
                win_class = "win" if row['å‹æ•—'] == 'WIN' else "loss" if row['å‹æ•—'] == 'LOSS' else "even"
                
                # å„å€¤ã®å®‰å…¨ãªå–å¾—ï¼ˆNaNå¯¾ç­–ï¼‰
                entry_price = row['Entryä¾¡æ ¼'] if pd.notna(row['Entryä¾¡æ ¼']) else ""
                entry_price_fmt = f"{entry_price:.3f}" if isinstance(entry_price, (int, float)) else entry_price
                
                exit_price = row['Exitä¾¡æ ¼'] if pd.notna(row['Exitä¾¡æ ¼']) else ""
                exit_price_fmt = f"{exit_price:.3f}" if isinstance(exit_price, (int, float)) else exit_price
                
                pips = row['pips'] if pd.notna(row['pips']) else ""
                pips_fmt = f"{pips:.1f}" if isinstance(pips, (int, float)) else pips
                
                no = row.get('No', idx+1)
                currency = row['é€šè²¨ãƒšã‚¢'] if pd.notna(row['é€šè²¨ãƒšã‚¢']) else ""
                direction = row['æ–¹å‘'] if pd.notna(row['æ–¹å‘']) else ""
                entry = row['Entry'] if pd.notna(row['Entry']) else ""
                win_loss = row['å‹æ•—'] if pd.notna(row['å‹æ•—']) else ""
                
                html_content += f"""
                    <tr>
                        <td>{no}</td>
                        <td>{currency}</td>
                        <td>{direction}</td>
                        <td>{entry}</td>
                """
                
                # Exitã‚«ãƒ©ãƒ ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
                if 'Exit' in df.columns:
                    exit_col = row['Exit'] if pd.notna(row['Exit']) else ""
                    html_content += f"<td>{exit_col}</td>"
                
                html_content += f"""
                        <td>{entry_price_fmt}</td>
                        <td>{exit_price_fmt}</td>
                        <td class="{win_class}">{win_loss}</td>
                        <td class="{win_class}">{pips_fmt}</td>
                    </tr>
                """
            
            html_content += f"""
                </table>
                
                <h2>ã‚°ãƒ©ãƒ•</h2>
                <img src="charts/{self.config['output_prefix']}_{file_date}.png" alt="FXå–å¼•çµæœã‚°ãƒ©ãƒ•">
                
                <div class="analysis-info">
                    <h2>ğŸ“ æ³¨æ„äº‹é …</h2>
                    <p>â€¢ ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯{file_date}ã®{self.config['name']}ã‚’åˆ†æã—ãŸçµæœã§ã™</p>
                    <p>â€¢ è‡ªå‹•çš„ã«æœªå‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡ºã—ã€ä¸€æ‹¬å‡¦ç†ã‚’å®Ÿè¡Œã—ã¦ã„ã¾ã™</p>
                    <p>â€¢ outputå´ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã™ã‚‹ã“ã¨ã§ã€å†åˆ†æãŒå¯èƒ½ã§ã™</p>
                </div>
            </body>
            </html>
            """
            
            # HTMLãƒ¬ãƒãƒ¼ãƒˆã®ä¿å­˜
            html_path = os.path.join(self.config['output_dir'], f"{self.config['output_prefix']}_{file_date}.html")
            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(html_content)
                
            self.logger.info(f"HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: {html_path}")
        
        except Exception as e:
            self.logger.error(f"HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            self.logger.error(traceback.format_exc())

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description='FXçµæœåˆ†æãƒ„ãƒ¼ãƒ«ï¼ˆä¸€æ‹¬å‡¦ç†ç‰ˆï¼‰')
    parser.add_argument('--type', choices=['yokubari', 'standard', 'both'], default='both',
                        help='åˆ†æã™ã‚‹ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã®ã‚¿ã‚¤ãƒ— (default: both - ä¸¡æ–¹å®Ÿè¡Œ)')
    
    args = parser.parse_args()
    
    try:
        if args.type == 'both':
            # ä¸¡æ–¹ã®ã‚¿ã‚¤ãƒ—ã‚’å‡¦ç†
            print("ğŸš€ FXçµæœåˆ†æã‚’é–‹å§‹ã—ã¾ã™ï¼ˆã‚ˆãã°ã‚Šã‚¨ãƒ³ãƒˆãƒªãƒ¼ + æ¨™æº–ã‚¨ãƒ³ãƒˆãƒªãƒ¼ï¼‰")
            print("ğŸ“… å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯: inputå´å­˜åœ¨ âˆ§ outputå´æœªå­˜åœ¨ â†’ è‡ªå‹•åˆ†æ")
            print("ğŸ’¡ åˆ©ä¾¿æ€§: outputå´å‰Šé™¤ â†’ å†åˆ†æå¯èƒ½")
            
            success_count = 0
            total_count = 2
            
            # ã‚ˆãã°ã‚Šã‚¨ãƒ³ãƒˆãƒªãƒ¼åˆ†æ
            print("\n" + "="*60)
            print("ğŸ“Š Step 1/2: ã‚ˆãã°ã‚Šã‚¨ãƒ³ãƒˆãƒªãƒ¼åˆ†æé–‹å§‹")
            print("="*60)
            try:
                analyzer_yokubari = FXResultAnalyzer(entry_type='yokubari')
                if analyzer_yokubari.process_all_unprocessed_files():
                    print("âœ… ã‚ˆãã°ã‚Šã‚¨ãƒ³ãƒˆãƒªãƒ¼åˆ†æå®Œäº†")
                    success_count += 1
                else:
                    print("âš ï¸  ã‚ˆãã°ã‚Šã‚¨ãƒ³ãƒˆãƒªãƒ¼åˆ†æã§ä¸€éƒ¨å¤±æ•—")
            except Exception as e:
                print(f"âŒ ã‚ˆãã°ã‚Šã‚¨ãƒ³ãƒˆãƒªãƒ¼åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            
            # æ¨™æº–ã‚¨ãƒ³ãƒˆãƒªãƒ¼åˆ†æ
            print("\n" + "="*60)
            print("ğŸ“Š Step 2/2: æ¨™æº–ã‚¨ãƒ³ãƒˆãƒªãƒ¼åˆ†æé–‹å§‹")
            print("="*60)
            try:
                analyzer_standard = FXResultAnalyzer(entry_type='standard')
                if analyzer_standard.process_all_unprocessed_files():
                    print("âœ… æ¨™æº–ã‚¨ãƒ³ãƒˆãƒªãƒ¼åˆ†æå®Œäº†")
                    success_count += 1
                else:
                    print("âš ï¸  æ¨™æº–ã‚¨ãƒ³ãƒˆãƒªãƒ¼åˆ†æã§ä¸€éƒ¨å¤±æ•—")
            except Exception as e:
                print(f"âŒ æ¨™æº–ã‚¨ãƒ³ãƒˆãƒªãƒ¼åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            
            # å…¨ä½“çµæœ
            print("\n" + "="*60)
            print("ğŸ“‹ å…¨ä½“å‡¦ç†çµæœ")
            print("="*60)
            print(f"å‡¦ç†å®Œäº†: {success_count}/{total_count}")
            
            if success_count == total_count:
                print("ğŸ‰ ã™ã¹ã¦ã®åˆ†æãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
            elif success_count > 0:
                print("âš ï¸  ä¸€éƒ¨ã®åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚å¤±æ•—ã—ãŸåˆ†æã®ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            else:
                print("âŒ ã™ã¹ã¦ã®åˆ†æãŒå¤±æ•—ã—ã¾ã—ãŸã€‚è¨­å®šã¨ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                
        else:
            # å˜ä¸€ã‚¿ã‚¤ãƒ—ã‚’å‡¦ç†
            print(f"ğŸš€ FXçµæœåˆ†æã‚’é–‹å§‹ã—ã¾ã™ï¼ˆ{ENTRYPOINT_CONFIGS[args.type]['name']}ï¼‰")
            print(f"ğŸ“… å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯: inputå´å­˜åœ¨ âˆ§ outputå´æœªå­˜åœ¨ â†’ è‡ªå‹•åˆ†æ")
            print(f"ğŸ’¡ åˆ©ä¾¿æ€§: outputå´å‰Šé™¤ â†’ å†åˆ†æå¯èƒ½")
            print(f"ğŸ“ å…¥åŠ›: {ENTRYPOINT_CONFIGS[args.type]['input_dir']}")
            print(f"ğŸ“ å‡ºåŠ›: {ENTRYPOINT_CONFIGS[args.type]['output_dir']}")
            
            analyzer = FXResultAnalyzer(entry_type=args.type)
            
            if analyzer.process_all_unprocessed_files():
                print("âœ… ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«å‡¦ç†ã•ã‚Œã¾ã—ãŸ")
            else:
                print("âš ï¸  ä¸€éƒ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            
    except Exception as e:
        print(f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()